{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38fb219-01b9-48e2-8315-859324f832cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_scatter\n",
    "import time\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.nn import GATConv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import combinations\n",
    "from scipy.spatial.distance import cosine\n",
    "from collections import defaultdict, deque\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "from math import comb\n",
    "from tqdm import tqdm\n",
    "from deap import creator, base, tools\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_node_features = torch.load(\"./data/pt_data/model_features.pt\")\n",
    "\n",
    "model_target_edge_index = torch.load(\"./data/pt_data/edge_index.pt\").to(device)\n",
    "model_target_edge_attr = torch.load(\"./data/pt_data/edge_attr.pt\").to(device).float()\n",
    "target_node_features = torch.load(\"./data/pt_data/target_features.pt\")\n",
    "target_edge_index = torch.load(\"./data/pt_data/target_edge_index.pt\").to(device)\n",
    "target_edge_attr = torch.load(\"./data/pt_data/target_edge_attr.pt\").to(device).float()\n",
    "target_edge_dict = torch.load(\"./data/pt_data/target_edge_dict.pt\")\n",
    "\n",
    "for key in target_edge_dict.keys():\n",
    "    target_edge_dict[key] = (target_edge_dict[key][0].to(device).float(),\n",
    "                             target_edge_dict[key][1].to(device).float())\n",
    "\n",
    "def get_model_features(edge_index, model_features):\n",
    "    source_nodes = edge_index[0].tolist()\n",
    "    extracted_features = []\n",
    "\n",
    "    for model_id in source_nodes:\n",
    "        if model_id in model_features:\n",
    "            model_features_tensor = model_features[model_id].to(device).float()\n",
    "        else:\n",
    "            model_features_tensor = torch.zeros((768,), dtype=torch.float32, device=device)\n",
    "        extracted_features.append(model_features_tensor)\n",
    "\n",
    "    if len(extracted_features) == 0:\n",
    "        return torch.empty((0, 768), dtype=torch.float32, device=device)\n",
    "\n",
    "    model_feature_tensor = torch.stack(extracted_features).to(device).float()  # float32 に統一\n",
    "    return model_feature_tensor\n",
    "\n",
    "def get_target_features(edge_index, target_node_features):\n",
    "    target_nodes = edge_index[1].tolist()\n",
    "    extracted_features = []\n",
    "\n",
    "    for target_id in target_nodes:\n",
    "        if target_id in target_node_features:\n",
    "            target_features_tensor = target_node_features[target_id].to(device).float()\n",
    "        else:\n",
    "            target_features_tensor = torch.zeros((768,), dtype=torch.float32, device=device)\n",
    "        extracted_features.append(target_features_tensor)\n",
    "\n",
    "    if len(extracted_features) == 0:\n",
    "        return torch.empty((0, 768), dtype=torch.float32, device=device)\n",
    "\n",
    "    target_feature_tensor = torch.stack(extracted_features).to(device).float()\n",
    "    return target_feature_tensor\n",
    "\n",
    "loss_records = []\n",
    "\n",
    "edge_weight_list = []\n",
    "edge_weight_index_list = []\n",
    "\n",
    "model_node_features = get_model_features(model_target_edge_index, model_node_features)\n",
    "target_node_features = get_target_features(model_target_edge_index, target_node_features)\n",
    "\n",
    "model_in_channels = model_node_features.shape[1]\n",
    "target_in_channels = target_node_features.shape[1]\n",
    "edge_in_channels = model_target_edge_attr.shape[1]\n",
    "target_edge_in_channels = target_edge_attr.shape[1]\n",
    "\n",
    "class ModelTargetAttentionGAT(nn.Module):\n",
    "    def __init__(self, model_in_channels, target_in_channels, edge_in_channels, hidden_channels=256, heads=8, total_epochs=10):\n",
    "        super(ModelTargetAttentionGAT, self).__init__()\n",
    "\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.heads = heads\n",
    "        self.total_epochs = total_epochs\n",
    "\n",
    "        self.model_transform = nn.Linear(model_in_channels, heads * hidden_channels, bias=False)\n",
    "        self.target_transform = nn.Linear(target_in_channels, heads * hidden_channels, bias=False)\n",
    "\n",
    "        self.edge_attn_transform = nn.Linear(768, heads * hidden_channels, bias=False)  # 768 → 2048\n",
    "\n",
    "        self.gat_target = GATConv(heads * hidden_channels, hidden_channels, heads=heads, concat=True)\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm1d(2048, momentum=0.01)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048, momentum=0.01)\n",
    "        \n",
    "        self.prelu_m_t = nn.PReLU(num_parameters=heads)\n",
    "        self.prelu_m_n = nn.PReLU(num_parameters=heads)\n",
    "        self.prelu_t = nn.PReLU(num_parameters=heads)\n",
    "\n",
    "        self.temperature_m_t = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "        self.temperature_m_n = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "        self.temperature_t = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "\n",
    "        self.min_alpha, self.max_alpha = 0.05, 0.2\n",
    "        self.min_temp, self.max_temp = 0.5, 1.5\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.model_transform.weight)\n",
    "        nn.init.xavier_uniform_(self.target_transform.weight)\n",
    "        nn.init.xavier_uniform_(self.edge_attn_transform.weight)\n",
    "\n",
    "    def forward(self, model_x, target_x, edge_index, edge_attr):\n",
    "        model_x_proj = self.model_transform(model_x).view(-1, self.heads * self.hidden_channels)\n",
    "        target_x_proj = self.target_transform(target_x).view(-1, self.heads * self.hidden_channels)\n",
    "\n",
    "        model_x_proj = self.batch_norm1(model_x_proj)\n",
    "        target_x_proj = self.batch_norm2(target_x_proj)\n",
    "\n",
    "        model_x_proj = model_x_proj.view(-1, self.heads, self.hidden_channels)\n",
    "        target_x_proj = target_x_proj.view(-1, self.heads, self.hidden_channels)\n",
    "\n",
    "        max_valid_index = target_x_proj.shape[0] - 1\n",
    "        out_of_bounds_mask = edge_index[1] > max_valid_index\n",
    "\n",
    "        edge_attr_proj = edge_attr[:, :768] - edge_attr[:, 768:]\n",
    "\n",
    "        edge_attn_values = self.edge_attn_transform(edge_attr_proj)  # 768 → (8 * 256)\n",
    "        edge_attn_values = edge_attn_values.view(-1, self.heads, self.hidden_channels)  # (E, 8, 256)\n",
    "\n",
    "        selected_target_x_proj = target_x_proj.index_select(0, edge_index[1])\n",
    "\n",
    "        num_samples = 10\n",
    "        sample_indices = torch.randint(0, edge_index.shape[1], (num_samples,), device=edge_index.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.prelu_m_t.weight.data.clamp_(self.min_alpha, self.max_alpha)\n",
    "            self.prelu_m_n.weight.data.clamp_(self.min_alpha, self.max_alpha)\n",
    "            self.prelu_t.weight.data.clamp_(self.min_alpha, self.max_alpha)\n",
    "            \n",
    "        attn_m_t = torch.matmul(model_x_proj.index_select(0, edge_index[0]), edge_attn_values.transpose(-1, -2))\n",
    "        attn_m_t = attn_m_t.mean(dim=-1)\n",
    "        attn_m_t = self.prelu_m_t(attn_m_t)\n",
    "        attn_m_t = torch.softmax(attn_m_t / torch.clamp(self.temperature_m_t, self.min_temp, self.max_temp), dim=1)\n",
    "\n",
    "        attn_m_n = torch.matmul(model_x_proj.index_select(0, edge_index[0]), edge_attn_values.transpose(-1, -2))\n",
    "        attn_m_n = attn_m_n.mean(dim=-1)\n",
    "        attn_m_n = self.prelu_m_n(attn_m_n)\n",
    "        attn_m_n = torch.softmax(attn_m_n / torch.clamp(self.temperature_m_n, self.min_temp, self.max_temp), dim=1)\n",
    "\n",
    "        attn_t = torch.matmul(target_x_proj.index_select(0, edge_index[1]), edge_attn_values.transpose(-1, -2))\n",
    "        attn_t = attn_t.mean(dim=-1)\n",
    "        attn_t = self.prelu_t(attn_t)\n",
    "        attn_t = torch.softmax(attn_t / torch.clamp(self.temperature_t, self.min_temp, self.max_temp), dim=1)\n",
    "\n",
    "        unique_target_nodes = edge_index[1].unique()\n",
    "        target_x_proj = target_x_proj.view(edge_index.shape[1], 8, 256)\n",
    "        edge_attn_values = edge_attn_values.view(edge_index.shape[1], 8, 256)\n",
    "\n",
    "        target_x_new = (\n",
    "            attn_m_n.unsqueeze(-1) * target_x_proj\n",
    "            + attn_m_t.unsqueeze(-1) * edge_attn_values\n",
    "            + attn_t.unsqueeze(-1) * target_x_proj\n",
    "        )\n",
    "\n",
    "        target_x_new = target_x_new.view(edge_index.shape[1], 2048)\n",
    "        target_x_new = torch_scatter.scatter_mean(\n",
    "            target_x_new.float(), edge_index[1], dim=0, dim_size=unique_target_nodes.shape[0]\n",
    "        )\n",
    "\n",
    "        attn_sum = attn_m_t + attn_m_n + attn_t\n",
    "        attn_score = torch_scatter.scatter_mean(attn_sum.float(), edge_index[1], dim=0, dim_size=unique_target_nodes.shape[0])\n",
    "        target_index = unique_target_nodes.tolist()\n",
    "        target_index = torch.tensor(target_index, dtype=torch.long, device=target_x_new.device)\n",
    "\n",
    "        return target_x_new, target_index, attn_score\n",
    "\n",
    "class FeatureEnhancement(nn.Module):\n",
    "    def __init__(self, in_channels=2048):\n",
    "        super(FeatureEnhancement, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels)\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels, momentum=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "class TargetFeatureEnhancement(nn.Module):\n",
    "    def __init__(self, in_channels=2048, out_channels=256):\n",
    "        super(TargetFeatureEnhancement, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_channels, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024, momentum=0.01)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512, momentum=0.01)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, out_channels)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels, momentum=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "class TargetDominationLayer(nn.Module):\n",
    "    def __init__(self, hidden_channels, init_decay=0.8):\n",
    "        super(TargetDominationLayer, self).__init__()\n",
    "\n",
    "        self.edge_fc = nn.Linear(768, 256, bias=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Q, _ = torch.linalg.qr(torch.randn(768, 256))\n",
    "            self.edge_fc.weight.copy_(Q.T)\n",
    "\n",
    "        self.edge_fc.weight.requires_grad = False\n",
    "\n",
    "        self.x_fc = nn.Linear(256, 256)  # 256 → 256\n",
    "        self.x_bn = nn.BatchNorm1d(256, momentum=0.01)\n",
    "\n",
    "    def forward(self, x, target_edge_index, target_edge_attr, target_index, target_x_new):\n",
    "        device = x.device  \n",
    "        x_j = x[target_index]\n",
    "        mask = torch.isin(target_edge_index[1], target_index)\n",
    "        sorted_mask_indices = torch.argsort(torch.searchsorted(target_index, target_edge_index[1][mask]))\n",
    "        mask_sorted = mask.nonzero(as_tuple=True)[0][sorted_mask_indices]  # `mask` に登録されたインデックスを並び替え\n",
    "        filtered_edge_index = target_edge_index[:, mask_sorted]\n",
    "        target_ids = filtered_edge_index[1]\n",
    "        source_ids = filtered_edge_index[0]\n",
    "        x_i = target_x_new[source_ids]\n",
    "        x_i_ave = torch_scatter.scatter_mean(\n",
    "            x_i.float(), target_index[target_ids], dim=0, dim_size=x.shape[0]\n",
    "        )\n",
    "        x_diff = x_i_ave - x_j\n",
    "        x_diff = self.x_fc(x_diff)\n",
    "        x_diff = self.x_bn(x_diff)\n",
    "        x_diff = F.relu(x_diff)\n",
    "\n",
    "        sorted_edge_attr = target_edge_attr[mask_sorted]\n",
    "        edge_attr_selected = torch_scatter.scatter_mean(\n",
    "            sorted_edge_attr.float(),\n",
    "            target_ids,\n",
    "            dim=0,\n",
    "            dim_size=x.shape[0]\n",
    "        )\n",
    "\n",
    "        edge_diff = edge_attr_selected[:, :768] - edge_attr_selected[:, 768:]\n",
    "        edge_diff = self.edge_fc(edge_diff)\n",
    "        edge_diff = (edge_diff - edge_diff.mean(dim=0)) / (edge_diff.std(dim=0) + 1e-6)\n",
    "        edge_diff = F.relu(edge_diff)\n",
    "\n",
    "        memory_applied = x_diff + x_j\n",
    "\n",
    "        return memory_applied, x_diff, edge_diff\n",
    "\n",
    "class DominationLayer(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(DominationLayer, self).__init__()\n",
    "\n",
    "        self.fc_dom_true = nn.Linear(768, 256, bias=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Q, _ = torch.linalg.qr(torch.randn(768, 256))\n",
    "            self.fc_dom_true.weight.copy_(Q.T)\n",
    "\n",
    "        self.fc_dom_true.weight.requires_grad = False\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_channels, 256)  \n",
    "        self.bn1 = nn.BatchNorm1d(256, momentum=0.01)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256, momentum=0.01)\n",
    "\n",
    "    def forward(self, x, target_index, target_edge_index, target_edge_attr, model_target_edge_index, target_node_features, memory_applied):\n",
    "        dom_Wj_list = []\n",
    "        Aj_mean_list = []\n",
    "\n",
    "        for Aj in target_index:\n",
    "            mask_Aj = target_edge_index[1] == Aj\n",
    "            selected_edges = target_edge_index[:, mask_Aj]\n",
    "            selected_edge_attr = target_edge_attr[mask_Aj]\n",
    "\n",
    "            if selected_edges.shape[1] == 0:\n",
    "                Wj = torch.ones((1,), device=target_edge_attr.device) * 1e-6\n",
    "                mask_Aj_in_features = model_target_edge_index[1] == Aj\n",
    "                Aj_features = target_node_features[mask_Aj_in_features]\n",
    "                if Aj_features.shape[0] > 1:\n",
    "                    Aj_mean = Aj_features.mean(dim=0, keepdim=True)\n",
    "                elif Aj_features.shape[0] == 1:\n",
    "                    Aj_mean = Aj_features.unsqueeze(0) if Aj_features.dim() == 1 else Aj_features\n",
    "                else:\n",
    "                    Aj_mean = torch.zeros((1, 768), device=target_edge_attr.device)\n",
    "\n",
    "                dom_Wj_list.append(Wj.unsqueeze(0))\n",
    "                Aj_mean_list.append(Aj_mean)\n",
    "                continue\n",
    "\n",
    "            Ai_ids = selected_edges[0]\n",
    "            unique_Ai_ids = Ai_ids.unique()\n",
    "            dim_size_Ai = unique_Ai_ids.shape[0]\n",
    "\n",
    "            Ai_j_ave_list = []\n",
    "            Aj_i_ave_list = []\n",
    "\n",
    "            for Ai in Ai_ids:\n",
    "                mask_Ai = selected_edges[0] == Ai\n",
    "                edge_attr_AiAj = selected_edge_attr[mask_Ai]\n",
    "                if edge_attr_AiAj.shape[0] > 1:\n",
    "                    Ai_j_ave = edge_attr_AiAj[:, :768].mean(dim=0, keepdim=True)\n",
    "                    Aj_i_ave = edge_attr_AiAj[:, 768:].mean(dim=0, keepdim=True)\n",
    "                else:\n",
    "                    Ai_j_ave = edge_attr_AiAj[:, :768] if edge_attr_AiAj.ndim > 1 else edge_attr_AiAj[:768].unsqueeze(0)\n",
    "                    Aj_i_ave = edge_attr_AiAj[:, 768:] if edge_attr_AiAj.ndim > 1 else edge_attr_AiAj[768:].unsqueeze(0)\n",
    "\n",
    "                Ai_j_ave_list.append(Ai_j_ave)\n",
    "                Aj_i_ave_list.append(Aj_i_ave)\n",
    "\n",
    "            if len(Ai_j_ave_list) > 1 and len(Aj_i_ave_list) > 1:\n",
    "                Ai_j_ave = torch.cat(Ai_j_ave_list, dim=0)\n",
    "                Aj_i_ave = torch.cat(Aj_i_ave_list, dim=0)\n",
    "            elif len(Ai_j_ave_list) == 1 and len(Aj_i_ave_list) == 1:\n",
    "                Ai_j_ave = Ai_j_ave_list[0]\n",
    "                Aj_i_ave = Aj_i_ave_list[0]\n",
    "            else:\n",
    "                Wj = torch.ones((1,), device=target_edge_attr.device) * 1e-6  # (1,)\n",
    "                mask_Aj_in_features = model_target_edge_index[1] == Aj\n",
    "                Aj_features = target_node_features[mask_Aj_in_features]\n",
    "                if Aj_features.shape[0] > 1:\n",
    "                    Aj_mean = Aj_features.mean(dim=0, keepdim=True)\n",
    "                else:\n",
    "                    Aj_mean = Aj_features.unsqueeze(0) if Aj_features.dim() == 1 else Aj_features\n",
    "\n",
    "                dom_Wj_list.append(Wj.unsqueeze(0))\n",
    "                Aj_mean_list.append(Aj_mean)\n",
    "                continue\n",
    "\n",
    "            mask_Aj_in_features = model_target_edge_index[1] == Aj\n",
    "            Aj_features = target_node_features[mask_Aj_in_features]\n",
    "            if Aj_features.shape[0] > 1:\n",
    "                Aj_mean = Aj_features.mean(dim=0, keepdim=True)\n",
    "            else:\n",
    "                Aj_mean = Aj_features.unsqueeze(0) if Aj_features.dim() == 1 else Aj_features\n",
    "\n",
    "            Ai_features_list = []\n",
    "            for Ai in Ai_ids:\n",
    "                mask_Ai = model_target_edge_index[1] == Ai\n",
    "                Ai_feature = target_node_features[mask_Ai]\n",
    "                if Ai_feature.shape[0] > 1:\n",
    "                    Ai_feature = Ai_feature.mean(dim=0, keepdim=True)\n",
    "                else:\n",
    "                    Ai_feature = Ai_feature.unsqueeze(0) if Ai_feature.dim() == 1 else Ai_feature\n",
    "    \n",
    "                Ai_features_list.append(Ai_feature)\n",
    "\n",
    "            if len(Ai_features_list) > 0:\n",
    "                Ai_mean = torch.cat(Ai_features_list, dim=0)\n",
    "            else:\n",
    "                Ai_mean = torch.empty((0, 768), device=target_node_features.device)\n",
    "\n",
    "            Aj_mean_expanded = Aj_mean.expand(dim_size_Ai, -1)\n",
    "\n",
    "            assert Ai_j_ave.shape == Aj_i_ave.shape, f\"Shape mismatch: Ai_j_ave={Ai_j_ave.shape}, Aj_i_ave={Aj_i_ave.shape}\"\n",
    "\n",
    "            if Ai_j_ave.numel() == 0 or Aj_i_ave.numel() == 0:\n",
    "                dom_Wj = torch.ones((1,), device=target_edge_attr.device) * 1e-6\n",
    "            else:\n",
    "                dist_Ai = torch.norm(Ai_mean - Ai_j_ave, dim=1)\n",
    "                dist_Aj = torch.norm(Aj_mean - Aj_i_ave, dim=1)\n",
    "                beta = 0.5\n",
    "                d_0 = 1\n",
    "                Wi = 1 / (1 + torch.exp(-beta * (dist_Ai - d_0)))\n",
    "                Wj = 1 / (1 + torch.exp(-beta * (dist_Aj - d_0)))\n",
    "                Wj = Wj.unsqueeze(0) if Wj.dim() == 0 else Wj\n",
    "                dom_Wj = Wj.mean(dim=0, keepdim=True)\n",
    "\n",
    "            dom_Wj_list.append(dom_Wj.unsqueeze(0) if dom_Wj.dim() == 1 else dom_Wj)\n",
    "            Aj_mean_list.append(Aj_mean.unsqueeze(0) if Aj_mean.dim() == 1 else Aj_mean)\n",
    "\n",
    "        dom_Wj = torch.cat(dom_Wj_list, dim=0)\n",
    "        Aj_mean = torch.cat(Aj_mean_list, dim=0)\n",
    "\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            domination_true = self.fc_dom_true(dom_Wj * Aj_mean)\n",
    "    \n",
    "        domination_true = (domination_true - domination_true.mean(dim=0)) / (domination_true.std(dim=0) + 1e-6)\n",
    "        domination_true = F.relu(domination_true)\n",
    "        dom_out = self.fc1(memory_applied)\n",
    "        dom_out = self.bn1(dom_out)\n",
    "        dom_out = F.relu(dom_out)\n",
    "        dom_out = self.fc2(dom_out)\n",
    "        dom_out = self.bn2(dom_out)\n",
    "        dom_out = F.relu(dom_out)\n",
    "        return dom_out, domination_true\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, model_in_channels, target_in_channels, edge_in_channels, target_edge_in_channels, total_epochs):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.hidden_channels = 256\n",
    "        self.heads = 8\n",
    "        self.model_target_gat = ModelTargetAttentionGAT(\n",
    "            model_in_channels, target_in_channels, edge_in_channels, \n",
    "            self.hidden_channels, self.heads, total_epochs\n",
    "        )\n",
    "\n",
    "        self.feature_enhancement_target = FeatureEnhancement(self.heads * self.hidden_channels)\n",
    "        self.target_feature_enhancement = TargetFeatureEnhancement(self.heads * self.hidden_channels, self.hidden_channels)\n",
    "        self.target_domination = TargetDominationLayer(self.hidden_channels)\n",
    "        self.domination_layer = DominationLayer(self.hidden_channels)\n",
    "\n",
    "    def forward(self, model_x, target_x, model_target_edge_index, model_target_edge_attr, target_edge_index, target_edge_attr):\n",
    "        target_x_new, target_index, attn_score = self.model_target_gat(model_x, target_x, model_target_edge_index, model_target_edge_attr)\n",
    "        target_x_new = self.feature_enhancement_target(target_x_new)\n",
    "        target_x_new = self.target_feature_enhancement(target_x_new)\n",
    "        memory_applied, x_diff, edge_diff = self.target_domination(target_x_new, target_edge_index, target_edge_attr, target_index, target_x_new)\n",
    "        dom_out, domination_true = self.domination_layer(memory_applied, target_index, target_edge_index, target_edge_attr, model_target_edge_index, target_node_features, memory_applied)\n",
    "\n",
    "        return attn_score, memory_applied, x_diff, edge_diff, dom_out, domination_true, target_index\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gnn_model = torch.load(\"./data/gnn_data/gnn_model_final.pt\", map_location=device)\n",
    "gnn_model.eval()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "with torch.no_grad():\n",
    "    attn_score, memory_applied, x_diff, edge_diff, dom_out, domination_true, target_index = gnn_model(\n",
    "        model_node_features,\n",
    "        target_node_features,\n",
    "        model_target_edge_index,\n",
    "        model_target_edge_attr,\n",
    "        target_edge_index,\n",
    "        target_edge_attr\n",
    "    )\n",
    "\n",
    "input_edge_index = torch.load(\"./data/input_data/input_pt_data/input_edge_index.pt\").to(device)\n",
    "input_edge_attr = torch.load(\"./data/input_data/input_pt_data/input_edge_attr.pt\").to(device)\n",
    "input_target_edge_index = torch.load(\"./data/input_data/input_pt_data/input_target_edge_index.pt\").to(device)\n",
    "input_target_edge_attr = torch.load(\"./data/input_data/input_pt_data/input_target_edge_attr.pt\").to(device)\n",
    "\n",
    "def find_matching_edges_by_src(input_edge_index, model_target_edge_index):\n",
    "    print(f\"[INFO] input_edge_index shape: {input_edge_index.shape}\")\n",
    "    print(f\"[INFO] model_target_edge_index shape: {model_target_edge_index.shape}\")\n",
    "\n",
    "    input_src_nodes = set(input_edge_index[0].tolist())\n",
    "    print(f\"[INFO] Number of unique src nodes in input: {len(input_src_nodes)}\")\n",
    "\n",
    "    matching_indices = []\n",
    "    for i in range(model_target_edge_index.shape[1]):\n",
    "        src_node = model_target_edge_index[0, i].item()\n",
    "        if src_node in input_src_nodes:\n",
    "            matching_indices.append(i)\n",
    "\n",
    "    print(f\"[RESULT] Total matching edges found: {len(matching_indices)}\")\n",
    "    return torch.tensor(matching_indices, dtype=torch.long, device=model_target_edge_index.device)\n",
    "\n",
    "matching_indices = find_matching_edges_by_src(input_edge_index, model_target_edge_index)\n",
    "selected_model_features = model_target_edge_attr[matching_indices, :768]\n",
    "print(f\"[INFO] Selected model features shape: {selected_model_features.shape}\")\n",
    "\n",
    "unique_model_features = torch.unique(selected_model_features, dim=0)\n",
    "print(f\"[RESULT] Unique model features extracted: {unique_model_features.shape[0]}\")\n",
    "\n",
    "input_source_features_ave = input_edge_attr[:, :768].mean(dim=0)\n",
    "\n",
    "def find_top_similar_vectors(unique_features, target_feature_ave, top_k=5):\n",
    "    similarities = []\n",
    "    for i, vec in enumerate(unique_features):\n",
    "        sim = 1 - cosine(vec.cpu().numpy(), target_feature_ave.cpu().numpy())\n",
    "        similarities.append((sim, i))\n",
    "\n",
    "    similarities.sort(reverse=True)\n",
    "\n",
    "    top_k_similarities = similarities[:top_k]\n",
    "    top_indices = [idx for _, idx in top_k_similarities]\n",
    "\n",
    "    print(f\"[INFO] Top {top_k} similarities selected:\")\n",
    "    for rank, (sim, idx) in enumerate(top_k_similarities, 1):\n",
    "        print(f\"  {rank:2d}: Index {idx}, Similarity = {sim:.4f}\")\n",
    "\n",
    "    return torch.stack([unique_features[i] for i in top_indices])\n",
    "\n",
    "best_comb_in_unique = find_top_similar_vectors(unique_model_features, input_source_features_ave, top_k=5)\n",
    "\n",
    "matched_attr_list = []\n",
    "matched_targets = []\n",
    "\n",
    "for vec in best_comb_in_unique:\n",
    "    match_mask = (model_target_edge_attr[:, :768] == vec).all(dim=1)\n",
    "    matches = match_mask.nonzero(as_tuple=True)[0]\n",
    "\n",
    "    if len(matches) > 0:\n",
    "        matched_attr_list.append(model_target_edge_attr[matches])\n",
    "        matched_targets.append(model_target_edge_index[1][matches])\n",
    "\n",
    "matched_attr = torch.cat(matched_attr_list, dim=0)\n",
    "matched_target_ids = torch.cat(matched_targets, dim=0)\n",
    "primary_target_features_raw = matched_attr[:, 768:]\n",
    "\n",
    "sorted_ids, sorted_indices = torch.sort(matched_target_ids)\n",
    "sorted_features = primary_target_features_raw[sorted_indices]\n",
    "\n",
    "unique_ids, counts = torch.unique_consecutive(sorted_ids, return_counts=True)\n",
    "\n",
    "split_features = torch.split(sorted_features, counts.tolist())\n",
    "mean_features = torch.stack([group.mean(dim=0) for group in split_features])\n",
    "\n",
    "primary_target_features_index = unique_ids.unsqueeze(1)\n",
    "primary_target_features_attr = mean_features\n",
    "print(f\"[LOG] primary_target_features_index shape: {primary_target_features_index.shape}\")\n",
    "print(f\"[LOG] primary_target_features_attr shape: {primary_target_features_attr.shape}\")\n",
    "\n",
    "assert primary_target_features_index.shape[1] == 1\n",
    "assert primary_target_features_attr.shape[1] == 768\n",
    "\n",
    "attn_weights = attn_score[primary_target_features_index.squeeze()]\n",
    "if attn_weights.ndim == 2:\n",
    "    attn_weights = attn_weights.mean(dim=1)\n",
    "\n",
    "print(\"[LOG] Before applying attention weights:\")\n",
    "print(\"First vector (first 6 dims):\", primary_target_features_attr[0][:6].tolist())\n",
    "print(\"Last vector (last 6 dims):\", primary_target_features_attr[-1][-6:].tolist())\n",
    "\n",
    "primary_target_features_attr *= attn_weights.unsqueeze(1)\n",
    "\n",
    "print(\"[LOG] After applying attention weights:\")\n",
    "print(\"First vector (first 6 dims):\", primary_target_features_attr[0][:6].tolist())\n",
    "print(\"Last vector (last 6 dims):\", primary_target_features_attr[-1][-6:].tolist())\n",
    "\n",
    "def determine_directed_edges_from_dom_out(dom_out, target_index, target_edge_index, target_edge_attr):\n",
    "    def compute_dom_strength(vecs):\n",
    "        return torch.tensor([\n",
    "            vec[vec > 0].mean().item() if (vec > 0).any() else 0.0\n",
    "            for vec in vecs\n",
    "        ], device=vecs.device)\n",
    "\n",
    "    dom_strength_partial = compute_dom_strength(dom_out)\n",
    "\n",
    "    num_nodes = target_edge_index.max().item() + 1\n",
    "    dom_strength_full = torch.zeros(num_nodes, device=dom_out.device)\n",
    "    dom_strength_full[target_index] = dom_strength_partial  # shape: (num_nodes,)\n",
    "\n",
    "    src_strength = dom_strength_full[target_edge_index[0]]  # shape: (E,)\n",
    "    tgt_strength = dom_strength_full[target_edge_index[1]]  # shape: (E,)\n",
    "\n",
    "    keep_mask = src_strength > tgt_strength\n",
    "    keep_edges_index = target_edge_index[:, keep_mask]\n",
    "    keep_edges_attr = target_edge_attr[keep_mask]\n",
    "    print(f\"[LOG] keep_edges_index shape: {keep_edges_index.shape}\")\n",
    "    print(f\"[LOG] keep_edges_attr shape: {keep_edges_attr.shape}\")\n",
    "\n",
    "    return keep_edges_index, keep_edges_attr\n",
    "\n",
    "keep_edges_index, keep_edges_attr = determine_directed_edges_from_dom_out(\n",
    "    dom_out, target_index, target_edge_index, target_edge_attr\n",
    ")\n",
    "\n",
    "def build_edge_lookup(keep_edges_index, keep_edges_attr):\n",
    "    edge_lookup = defaultdict(list)\n",
    "    edge_attr_dict = defaultdict(list)\n",
    "\n",
    "    for i in range(keep_edges_index.shape[1]):\n",
    "        src = int(keep_edges_index[0, i].item())\n",
    "        tgt = int(keep_edges_index[1, i].item())\n",
    "\n",
    "        edge_lookup[(src, tgt)].append(i)\n",
    "        edge_attr_dict[(src, tgt)].append(keep_edges_attr[i])  # tensor of shape (1536,)\n",
    "\n",
    "    print(f\"[LOG] edge_lookup constructed: {len(edge_lookup)} unique (src, tgt) pairs\")\n",
    "    for i, ((src, tgt), idx_list) in enumerate(edge_lookup.items()):\n",
    "        print(f\"  [edge_lookup] ({src}, {tgt}) -> edge indices: {idx_list}\")\n",
    "        if i >= 9:\n",
    "            print(\"  ... (truncated)\")\n",
    "            break\n",
    "\n",
    "    print(f\"[LOG] edge_attr_dict constructed: {len(edge_attr_dict)} unique (src, tgt) pairs\")\n",
    "    for i, ((src, tgt), attr_list) in enumerate(edge_attr_dict.items()):\n",
    "        print(f\"  [edge_attr_dict] ({src}, {tgt}) -> attr[0][:3]: {attr_list[0][:3].tolist()} (1st only)\")\n",
    "        if i >= 9:\n",
    "            print(\"  ... (truncated)\")\n",
    "            break\n",
    "\n",
    "    return edge_lookup, edge_attr_dict\n",
    "\n",
    "edge_lookup, edge_attr_dict = build_edge_lookup(keep_edges_index, keep_edges_attr)\n",
    "\n",
    "def edge_attr_dict_to_tensor(edge_attr_dict):\n",
    "    start_time = time.time()\n",
    "    edge_attr_list = []\n",
    "    edge_index_list = []\n",
    "\n",
    "    for (src, tgt), attr_list in edge_attr_dict.items():\n",
    "        for attr in attr_list:\n",
    "            edge_index_list.append([src, tgt])\n",
    "            edge_attr_list.append(attr)\n",
    "\n",
    "    edge_index = torch.tensor(edge_index_list).T  # shape: (2, E)\n",
    "    edge_attr_tensor = torch.stack(edge_attr_list, dim=0)  # shape: (E, F)\n",
    "    print(f\"[LOG] edge_attr_dict_to_tensor completed in {time.time() - start_time:.2f}s\")\n",
    "    return edge_index, edge_attr_tensor\n",
    "\n",
    "def generate_paths_tensor_cpu(primary_index, input_edge_index, edge_index,\n",
    "                              MAX_PATH_LENGTH=50, MAX_QUEUE_SIZE=1000000, GOAL_DISTANCE_THRESHOLD=2):\n",
    "    goal_nodes = set(input_edge_index[1].unique().tolist())\n",
    "    num_nodes = edge_index.max().item() + 1\n",
    "\n",
    "    paths_by_start = defaultdict(list)\n",
    "\n",
    "    for start_tensor in primary_index:\n",
    "        start_node = int(start_tensor.item())\n",
    "        queue = deque()\n",
    "        queue.append((start_node, [], set()))  # (current_node, path, used_edges)\n",
    "        visited_state = set()\n",
    "        reached_goals = set()\n",
    "\n",
    "        step = 0\n",
    "        while queue:\n",
    "            if len(queue) > MAX_QUEUE_SIZE:\n",
    "                print(f\"[WARNING] Queue size exceeded limit at start node {start_node}. Forcing early termination.\")\n",
    "                break\n",
    "\n",
    "            current_node, path, used_edges = queue.popleft()\n",
    "            key = (current_node, frozenset(used_edges))\n",
    "            if key in visited_state:\n",
    "                continue\n",
    "            visited_state.add(key)\n",
    "\n",
    "            if len(path) >= MAX_PATH_LENGTH:\n",
    "                continue\n",
    "\n",
    "            mask = edge_index[0] == current_node\n",
    "            next_edges = edge_index[:, mask]\n",
    "            edge_indices = torch.nonzero(mask, as_tuple=False).squeeze()\n",
    "\n",
    "            if next_edges.ndim == 1:\n",
    "                next_edges = next_edges.unsqueeze(1)\n",
    "            if edge_indices.ndim == 0:\n",
    "                edge_indices = [edge_indices.item()]\n",
    "            elif isinstance(edge_indices, torch.Tensor):\n",
    "                edge_indices = edge_indices.tolist()\n",
    "\n",
    "            for idx, (src, tgt) in zip(edge_indices, next_edges.T):\n",
    "                src_item = src.item()\n",
    "                tgt_item = tgt.item()\n",
    "\n",
    "                if idx in used_edges:\n",
    "                    continue\n",
    "\n",
    "                if len(path) == 0:\n",
    "                    if src_item != start_node:\n",
    "                        continue\n",
    "                else:\n",
    "                    prev_edge = path[-1]\n",
    "                    prev_tgt = edge_index[1, prev_edge].item()\n",
    "                    if src_item != prev_tgt:\n",
    "                        continue\n",
    "\n",
    "                new_path = path + [idx]\n",
    "                new_used = used_edges | {idx}\n",
    "                queue.append((tgt_item, new_path, new_used))\n",
    "\n",
    "                if tgt_item in goal_nodes and len(new_path) > 0:\n",
    "                    try:\n",
    "                        node_seq = [edge_index[0, new_path[0]].item()]\n",
    "                        for e_idx in new_path:\n",
    "                            node_seq.append(edge_index[1, e_idx].item())\n",
    "                    except Exception as e:\n",
    "                        print(f\"[WARNING] Failed to reconstruct node path: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    if node_seq[0] != start_node:\n",
    "                        print(f\"[WARNING] Path ignored: node_seq[0] != start_node ({node_seq[0]} != {start_node})\")\n",
    "                        continue\n",
    "\n",
    "                    if node_seq[-1] != tgt_item:\n",
    "                        print(f\"[WARNING] Path ignored: node_seq[-1] != goal ({node_seq[-1]} != {tgt_item})\")\n",
    "                        continue\n",
    "\n",
    "                    paths_by_start[start_node].append(new_path)\n",
    "                    reached_goals.add(tgt_item)\n",
    "\n",
    "            step += 1\n",
    "            if step % 100000 == 0 or not queue or step == 1:\n",
    "                print(f\"[DEBUG] {start_node}: Step {step}, Queue size: {len(queue)}\")\n",
    "\n",
    "        total_edges = sum(len(path) for path in paths_by_start[start_node])\n",
    "        used_nodes = set()\n",
    "        for path in paths_by_start[start_node]:\n",
    "            for idx in path:\n",
    "                src = edge_index[0, idx].item()\n",
    "                tgt = edge_index[1, idx].item()\n",
    "                used_nodes.update([src, tgt])\n",
    "        print(f\"[RESULT] Start node {start_node}: {len(paths_by_start[start_node])} paths, \"\n",
    "              f\"{len(used_nodes)} nodes, {total_edges} total edges\")\n",
    "\n",
    "    print(f\"[LOG] paths_by_start summary: {len(paths_by_start)} start nodes\")\n",
    "    for i, (start, paths) in enumerate(paths_by_start.items()):\n",
    "        print(f\"  [paths_by_start] Start node: {start}, #paths: {len(paths)}\")\n",
    "        for j, path in enumerate(paths[:2]):\n",
    "            try:\n",
    "                node_seq = [edge_index[0, path[0]].item()]\n",
    "                for e_idx in path:\n",
    "                    node_seq.append(edge_index[1, e_idx].item())\n",
    "                node_seq_str = ', '.join(map(str, node_seq))\n",
    "                print(f\"    Path {j}: {path} | Nodes: [{node_seq_str}]\")\n",
    "            except Exception as e:\n",
    "                print(f\"    Path {j}: {path} | [ERROR reconstructing node path: {e}]\")\n",
    "        if i >= 4:\n",
    "            print(\"  ... (truncated)\")\n",
    "            break\n",
    "    \n",
    "    return paths_by_start\n",
    "\n",
    "edge_index, edge_attr_tensor = edge_attr_dict_to_tensor(edge_attr_dict)\n",
    "\n",
    "paths_by_start = generate_paths_tensor_cpu(\n",
    "    primary_index=primary_target_features_index,\n",
    "    input_edge_index=input_edge_index,\n",
    "    edge_index=edge_index\n",
    ")\n",
    "\n",
    "final_paths_by_start = paths_by_start\n",
    "\n",
    "for start_node in list(paths_by_start.keys())[:10]:\n",
    "    print(f\"[CHECK] Start node {start_node}\")\n",
    "    print(f\"  - Total paths before filtering: {len(paths_by_start[start_node])}\")\n",
    "    print(f\"  - Total paths after filtering: {len(final_paths_by_start.get(start_node, []))}\")\n",
    "\n",
    "def compute_total_loss_with_paths(final_paths_by_start, edge_index, edge_attr_tensor,\n",
    "                                  primary_dict, input_edge_index, input_edge_attr, node_dim=768):\n",
    "\n",
    "    goal_index = input_edge_index[1]\n",
    "    goal_features = input_edge_attr[:, node_dim:]\n",
    "    node_goal_features = {\n",
    "        int(goal_index[i].item()): goal_features[i]\n",
    "        for i in range(goal_index.size(0))\n",
    "    }\n",
    "\n",
    "    pred_node_states = defaultdict(list)\n",
    "    path_contributions = []\n",
    "\n",
    "    for start_idx, (start, paths) in enumerate(final_paths_by_start.items(), 1):\n",
    "        print(f\"[TRACE] Processing start node {start} ({start_idx}/{len(final_paths_by_start)}) with {len(paths)} paths\")\n",
    "        for path_idx, edge_idx_path in enumerate(paths):\n",
    "            if not edge_idx_path:\n",
    "                print(f\"  [WARNING] Empty path at index {path_idx}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Start node consistency check\n",
    "            first_edge = edge_idx_path[0]\n",
    "            src_check = None\n",
    "            src_check = int(edge_index[0, first_edge].item())\n",
    "\n",
    "            if src_check != start:\n",
    "                print(f\"  [WARNING] Path {path_idx} does not start from start node {start}, but from {src_check}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            edge_feat_cache = {}\n",
    "            node_state = {}\n",
    "\n",
    "            for i, edge_idx in enumerate(edge_idx_path):\n",
    "                src = tgt = None\n",
    "                try:\n",
    "                    src = int(edge_index[0, edge_idx].item())\n",
    "                    tgt = int(edge_index[1, edge_idx].item())\n",
    "                except IndexError:\n",
    "                    print(f\"    [WARNING] Edge index {edge_idx} out of bounds in edge_index. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                if i == 0:\n",
    "                    if src in primary_dict:\n",
    "                        node_state[src] = primary_dict[src].clone()\n",
    "                    else:\n",
    "                        print(f\"    [WARNING] Source node {src} not in primary_dict. Skipping path.\")\n",
    "                        break\n",
    "                elif src not in node_state:\n",
    "                    print(f\"    [WARNING] Source node {src} not in node_state during path. Skipping path.\")\n",
    "                    break\n",
    "\n",
    "                if edge_idx not in edge_feat_cache:\n",
    "                    edge_feat_cache[edge_idx] = edge_attr_tensor[edge_idx, node_dim:]\n",
    "                edge_feat = edge_feat_cache[edge_idx]\n",
    "\n",
    "                delta = node_state[src] - edge_feat\n",
    "                updated_feat = delta + edge_feat\n",
    "                node_state[tgt] = updated_feat\n",
    "\n",
    "            last_edge_idx = edge_idx_path[-1]\n",
    "            final_tgt = None\n",
    "            try:\n",
    "                final_tgt = int(edge_index[1, last_edge_idx].item())\n",
    "            except IndexError:\n",
    "                print(f\"  [WARNING] Final edge index {last_edge_idx} out of bounds. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            if final_tgt is not None and final_tgt in node_goal_features and final_tgt in node_state:\n",
    "                pred_node_states[final_tgt].append(node_state[final_tgt])\n",
    "                path_contributions.append((start, final_tgt, node_state[final_tgt], edge_idx_path))\n",
    "            else:\n",
    "                print(f\"  [WARNING] Final target {final_tgt} not in goal or node_state. Skipping.\")\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for node, goal_feat in node_goal_features.items():\n",
    "        if node in pred_node_states:\n",
    "            pred_avg = torch.stack(pred_node_states[node], dim=0).mean(dim=0)\n",
    "            loss = torch.norm(pred_avg - goal_feat, p=2)\n",
    "        else:\n",
    "            loss = torch.norm(torch.zeros_like(goal_feat) - goal_feat, p=2)\n",
    "            print(f\"[WARNING] Goal node {node} not reached. Using zero vector for loss.\")\n",
    "        print(f\"[RESULT] Loss for goal node {node}: {loss.item():.4f}\")\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"[RESULT] Total loss: {total_loss:.4f}\")\n",
    "    \n",
    "    seen_starts = set()\n",
    "    printed = 0\n",
    "\n",
    "    for (start_node, final_tgt, feat, edge_idx_path) in path_contributions:\n",
    "        if start_node not in seen_starts:\n",
    "            seen_starts.add(start_node)\n",
    "            printed = 0\n",
    "        if printed >= 2:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            node_seq = [int(edge_index[0, edge_idx_path[0]].item())]\n",
    "            for edge_idx in edge_idx_path:\n",
    "                node_seq.append(int(edge_index[1, edge_idx].item()))\n",
    "        except Exception as e:\n",
    "            print(f\"  [ERROR] Failed to reconstruct node sequence for path starting at {start_node}: {e}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  [PATH] Start: {start_node}, Goal: {final_tgt}, Nodes: {node_seq}, Path: {edge_idx_path}\")\n",
    "        printed += 1\n",
    "\n",
    "        if len(seen_starts) >= 10:\n",
    "            print(\"  ... (truncated)\")\n",
    "            break\n",
    "    \n",
    "    return total_loss, path_contributions, node_goal_features\n",
    "\n",
    "def compute_coverage_from_paths(path_contributions, node_goal_features, total_loss, edge_index, total_coverage=1.0):\n",
    "\n",
    "    epsilon = 1e-6\n",
    "    node_to_feats = defaultdict(list)\n",
    "    path_lookup = []\n",
    "\n",
    "    for i, (start_node, final_tgt, final_feat, edge_idx_path) in enumerate(path_contributions):\n",
    "        final_feat = final_feat.cpu()\n",
    "        path_lookup.append((i, start_node, final_tgt, final_feat, edge_idx_path))\n",
    "        node_to_feats[final_tgt].append(final_feat)\n",
    "\n",
    "    node_goal_features = {k: v.cpu() for k, v in node_goal_features.items()}\n",
    "\n",
    "    edge_contributions = {}\n",
    "\n",
    "    for path_id, start_node, final_tgt, final_feat, edge_idx_path in tqdm(path_lookup, desc=\"Computing path-wise coverage\"):\n",
    "        temp_node_feats = {k: [f.clone() for f in v] for k, v in node_to_feats.items()}\n",
    "\n",
    "        found = False\n",
    "        for i, t in enumerate(temp_node_feats[final_tgt]):\n",
    "            if torch.equal(final_feat, t):\n",
    "                del temp_node_feats[final_tgt][i]\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            print(f\"[WARNING] Path {path_id} contribution not found in node {final_tgt}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        new_loss = 0.0\n",
    "        for node, goal_feat in node_goal_features.items():\n",
    "            feats = temp_node_feats.get(node, [])\n",
    "            avg = torch.stack(feats, dim=0).mean(dim=0) if feats else torch.zeros_like(goal_feat)\n",
    "            new_loss += torch.norm(avg - goal_feat, p=2).item()\n",
    "\n",
    "        coverage = new_loss - total_loss\n",
    "        edge_contributions[path_id] = coverage\n",
    "\n",
    "    top_paths = sorted(edge_contributions.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    print(\"[SUMMARY] Top 10 most beneficial paths (positive ΔLoss):\")\n",
    "\n",
    "    for path_id, cov in top_paths:\n",
    "        try:\n",
    "            _, start_node, final_tgt, _, edge_idx_path = path_lookup[path_id]\n",
    "\n",
    "            # ノード列を順序付きで再構成\n",
    "            node_seq = []\n",
    "            if edge_idx_path:\n",
    "                first_src = int(edge_index[0, edge_idx_path[0]].item())\n",
    "                node_seq.append(first_src)\n",
    "                for edge_idx in edge_idx_path:\n",
    "                    tgt = int(edge_index[1, edge_idx].item())\n",
    "                    node_seq.append(tgt)\n",
    "\n",
    "            node_ids_str = ', '.join(map(str, node_seq))\n",
    "            print(f\"  Path ID: {path_id} | Start: {start_node} | Nodes: [{node_ids_str}] | ΔLoss: {cov:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  [WARNING] Failed to log path {path_id}: {e}\")\n",
    "\n",
    "    return edge_contributions\n",
    "\n",
    "primary_dict = {\n",
    "    int(primary_target_features_index[i].item()): primary_target_features_attr[i]\n",
    "    for i in range(primary_target_features_index.size(0))\n",
    "}\n",
    "\n",
    "print(f\"[LOG] primary_dict constructed: {len(primary_dict)} entries\")\n",
    "for i, (k, v) in enumerate(primary_dict.items()):\n",
    "    print(f\"  [primary_dict] Node ID: {k}, Feature[:3]: {v[:3].tolist()}\")\n",
    "    if i >= 9:\n",
    "        print(\"  ... (truncated)\")\n",
    "        break\n",
    "\n",
    "goal_index = input_edge_index[1]\n",
    "goal_features = input_edge_attr[:, 768:]\n",
    "\n",
    "print(f\"[LOG] goal_index size: {goal_index.size(0)}, goal_features shape: {goal_features.shape}\")\n",
    "for i in range(min(10, goal_index.size(0))):\n",
    "    print(f\"  [goal_index] Node ID: {int(goal_index[i].item())}, Feature[:3]: {goal_features[i][:3].tolist()}\")\n",
    "\n",
    "node_goal_features = {\n",
    "    int(goal_index[i].item()): goal_features[i]\n",
    "    for i in range(goal_index.size(0))\n",
    "}\n",
    "\n",
    "print(f\"[LOG] node_goal_features constructed: {len(node_goal_features)} entries\")\n",
    "for i, (k, v) in enumerate(node_goal_features.items()):\n",
    "    print(f\"  [node_goal_features] Node ID: {k}, Feature[:3]: {v[:3].tolist()}\")\n",
    "    if i >= 9:\n",
    "        print(\"  ... (truncated)\")\n",
    "        break\n",
    "\n",
    "total_loss, path_contributions, node_goal_features = compute_total_loss_with_paths(\n",
    "    final_paths_by_start,\n",
    "    edge_index,\n",
    "    edge_attr_tensor,\n",
    "    primary_dict,\n",
    "    input_edge_index,\n",
    "    input_edge_attr\n",
    ")\n",
    "\n",
    "delta_loss = {}\n",
    "\n",
    "save_dir = \"./data/explor_data/YOUR_DIRECTORY_NAME_HERE\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(save_dir, \"found_paths.json\"), \"w\") as f:\n",
    "    json.dump({str(k): v for k, v in final_paths_by_start.items()}, f, indent=2)\n",
    "\n",
    "with open(os.path.join(save_dir, \"delta_loss.json\"), \"w\") as f:\n",
    "    json.dump({str(k): v for k, v in delta_loss.items()}, f, indent=2)\n",
    "\n",
    "torch.save(final_paths_by_start, os.path.join(save_dir, \"found_paths.pt\"))\n",
    "torch.save(delta_loss, os.path.join(save_dir, \"delta_loss.pt\"))\n",
    "\n",
    "save_path = os.path.join(save_dir, \"path_contributions.json\")\n",
    "\n",
    "path_contributions_serializable = [\n",
    "    {\n",
    "        \"start_node\": int(start_node),\n",
    "        \"final_tgt\": int(final_tgt),\n",
    "        \"edge_idx_path\": [int(e) for e in edge_idx_path]\n",
    "    }\n",
    "    for (start_node, final_tgt, feat, edge_idx_path) in path_contributions\n",
    "]\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(path_contributions_serializable, f, indent=2)\n",
    "\n",
    "print(f\"[LOG] Saved final_paths and coverage_result to {save_dir}\")\n",
    "\n",
    "creator.create(\"FitnessMulti\", base.Fitness, weights=(-1.0, 1.0))\n",
    "creator.create(\"Individual\", dict, fitness=creator.FitnessMulti)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "def convert_paths_to_target_edges(final_paths_by_start, edge_index, target_edge_index):\n",
    "    original_edge_lookup = {}\n",
    "    for idx in range(edge_index.size(1)):\n",
    "        key = (int(edge_index[0, idx].item()), int(edge_index[1, idx].item()))\n",
    "        original_edge_lookup[key] = idx\n",
    "\n",
    "    target_lookup = defaultdict(list)\n",
    "    for idx in range(target_edge_index.size(1)):\n",
    "        key = (int(target_edge_index[0, idx].item()), int(target_edge_index[1, idx].item()))\n",
    "        target_lookup[key].append(idx)\n",
    "\n",
    "    converted_paths_by_start = defaultdict(list)\n",
    "\n",
    "    for start_node, path_list in final_paths_by_start.items():\n",
    "        for edge_path in path_list:\n",
    "            target_edge_path = []\n",
    "            for edge_idx in edge_path:\n",
    "                # print(f\"[DEBUG] Before int cast: edge_idx = {edge_idx}, type={type(edge_idx)}\")\n",
    "                edge_idx = int(edge_idx) if isinstance(edge_idx, torch.Tensor) else edge_idx  # ← ここ追加！\n",
    "                src = int(edge_index[0, edge_idx].item())\n",
    "                tgt = int(edge_index[1, edge_idx].item())\n",
    "                key = (src, tgt)\n",
    "                if key in target_lookup:\n",
    "                    target_idx = int(target_lookup[key][0])  # ← ここもintに固定！\n",
    "                    target_edge_path.append(target_idx)\n",
    "                else:\n",
    "                    print(f\"[WARNING] No match in target_edge_index for ({src}->{tgt})\")\n",
    "                    break\n",
    "            else:\n",
    "                converted_paths_by_start[start_node].append(target_edge_path)\n",
    "\n",
    "    print(f\"[LOG] Conversion complete: {len(converted_paths_by_start)} start nodes\")\n",
    "    return converted_paths_by_start\n",
    "\n",
    "converted_paths_by_start = convert_paths_to_target_edges(\n",
    "    final_paths_by_start=final_paths_by_start,\n",
    "    edge_index=edge_index,\n",
    "    target_edge_index=target_edge_index\n",
    ")\n",
    "\n",
    "for i, (start_node, paths) in enumerate(converted_paths_by_start.items()):\n",
    "    print(f\"  Start Node: {start_node}, #Paths: {len(paths)}\")\n",
    "    for j, edge_path in enumerate(paths[:2]):  # 各スタートノードにつき2件だけ表示\n",
    "        print(f\"    Path {j}: {edge_path}\")\n",
    "    if i >= 4:\n",
    "        print(\"  ... (truncated)\")\n",
    "        break\n",
    "\n",
    "def unify_paths_simple(converted_paths_by_start, max_logs=5):\n",
    "    print(\"[LOG] Unifying paths by start node (simple deduplication)\")\n",
    "\n",
    "    unified_paths_by_start = defaultdict(list)\n",
    "\n",
    "    for start_node, paths in converted_paths_by_start.items():\n",
    "        seen_paths = set()\n",
    "\n",
    "        for edge_path in paths:\n",
    "            if not edge_path:\n",
    "                continue\n",
    "            path_key = tuple(edge_path)\n",
    "            if path_key not in seen_paths:\n",
    "                seen_paths.add(path_key)\n",
    "                unified_paths_by_start[start_node].append(list(path_key))\n",
    "\n",
    "    total_paths = sum(len(v) for v in unified_paths_by_start.values())\n",
    "    print(f\"[LOG] Unified paths generated: {total_paths} paths\")\n",
    "\n",
    "    printed = 0\n",
    "    for start_node, paths in unified_paths_by_start.items():\n",
    "        print(f\"  [Start Node {start_node}] ({len(paths)} paths)\")\n",
    "        for i, path in enumerate(paths):\n",
    "            print(f\"    Path {i}: {path}\")\n",
    "            printed += 1\n",
    "            if printed >= max_logs:\n",
    "                print(\"  ... (truncated)\")\n",
    "                return unified_paths_by_start  # 早期リターンで無駄な出力防止\n",
    "\n",
    "    return unified_paths_by_start\n",
    "\n",
    "unified_paths_by_start = unify_paths_simple(\n",
    "    converted_paths_by_start=converted_paths_by_start\n",
    ")\n",
    "\n",
    "def assign_edge_choices(edge_seq, target_edge_index, target_edge_attr, primary_target_features_attr, node_dim=768, similarity_threshold=0.8):\n",
    "    device = target_edge_attr.device\n",
    "    primary_target_features_attr = primary_target_features_attr.to(device)\n",
    "\n",
    "    edge_choice = []\n",
    "    prev_output_feat = None\n",
    "    prev_node = None\n",
    "\n",
    "    i = 0\n",
    "    while i < len(edge_seq):\n",
    "        edge_idx = int(edge_seq[i])\n",
    "        src = int(target_edge_index[0, edge_idx].item())\n",
    "        tgt = int(target_edge_index[1, edge_idx].item())\n",
    "        key = (src, tgt)\n",
    "        candidates = edge_cand_dict.get(key, [])\n",
    "\n",
    "        if not candidates:\n",
    "            print(f\"[WARNING] No candidates for key ({src}->{tgt}), using edge_idx {edge_idx} directly.\")\n",
    "            edge_choice.append(edge_idx)\n",
    "            prev_output_feat = target_edge_attr[edge_idx, node_dim:].to(device)\n",
    "            prev_node = tgt\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        if i == 0:\n",
    "            best_sim = -1.0\n",
    "            best_cand_idx = candidates[0]\n",
    "            for cand_edge_idx in candidates:\n",
    "                cand_src_feat = target_edge_attr[cand_edge_idx, :node_dim].to(device)\n",
    "                cos_sim = F.cosine_similarity(primary_target_features_attr, cand_src_feat, dim=0).item()\n",
    "                if cos_sim > best_sim:\n",
    "                    best_sim = cos_sim\n",
    "                    best_cand_idx = cand_edge_idx\n",
    "            edge_choice.append(best_cand_idx)\n",
    "            prev_output_feat = target_edge_attr[best_cand_idx, node_dim:].to(device)\n",
    "            prev_node = tgt\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        group = []\n",
    "        group_indices = []\n",
    "\n",
    "        j = i\n",
    "        while j < len(edge_seq):\n",
    "            next_edge_idx = int(edge_seq[j])\n",
    "            next_src = int(target_edge_index[0, next_edge_idx].item())\n",
    "            if next_src != prev_node:\n",
    "                break\n",
    "            group.append(next_edge_idx)\n",
    "            group_indices.append(j)\n",
    "            j += 1\n",
    "\n",
    "        if group:\n",
    "            for idx_in_group, group_edge_idx in zip(group_indices, group):\n",
    "                src = int(target_edge_index[0, group_edge_idx].item())\n",
    "                tgt = int(target_edge_index[1, group_edge_idx].item())\n",
    "                key = (src, tgt)\n",
    "                candidates = edge_cand_dict.get(key, [])\n",
    "\n",
    "                best_sim = -1.0\n",
    "                best_cand_idx = candidates[0] if candidates else group_edge_idx\n",
    "                for cand_edge_idx in candidates:\n",
    "                    cand_src_feat = target_edge_attr[cand_edge_idx, :node_dim].to(device)\n",
    "                    cos_sim = F.cosine_similarity(prev_output_feat, cand_src_feat, dim=0).item()\n",
    "                    if cos_sim > best_sim:\n",
    "                        best_sim = cos_sim\n",
    "                        best_cand_idx = cand_edge_idx\n",
    "\n",
    "                edge_choice.append(int(best_cand_idx))\n",
    "                prev_output_feat = target_edge_attr[best_cand_idx, node_dim:].to(device)\n",
    "                prev_node = tgt\n",
    "\n",
    "            i = j\n",
    "        else:\n",
    "            candidates = edge_cand_dict.get((src, tgt), [])\n",
    "            best_sim = -1.0\n",
    "            best_cand_idx = candidates[0] if candidates else edge_idx\n",
    "            for cand_edge_idx in candidates:\n",
    "                cand_src_feat = target_edge_attr[cand_edge_idx, :node_dim].to(device)\n",
    "                cos_sim = F.cosine_similarity(prev_output_feat, cand_src_feat, dim=0).item()\n",
    "                if cos_sim > best_sim:\n",
    "                    best_sim = cos_sim\n",
    "                    best_cand_idx = cand_edge_idx\n",
    "\n",
    "            edge_choice.append(int(best_cand_idx))\n",
    "            prev_output_feat = target_edge_attr[best_cand_idx, node_dim:].to(device)\n",
    "            prev_node = tgt\n",
    "            i += 1\n",
    "\n",
    "    return edge_choice\n",
    "\n",
    "def separate_individuals_by_goal(unified_paths_by_start, target_edge_index, target_edge_attr, primary_dict, primary_target_features_attr, primary_target_features_index, edge_cand_dict, similarity_threshold=0.8):\n",
    "    target_edge_index = target_edge_index.cpu()\n",
    "\n",
    "    primary_nodes = primary_target_features_index.squeeze(1).cpu().numpy().tolist()\n",
    "    start_node_to_row_idx = {node_id: idx for idx, node_id in enumerate(primary_nodes)}\n",
    "\n",
    "    goal_to_individuals = defaultdict(list)\n",
    "\n",
    "    for start_node, paths in unified_paths_by_start.items():\n",
    "        if start_node not in primary_dict:\n",
    "            print(f\"[WARNING] Start node {start_node} missing in primary_dict.\")\n",
    "            continue\n",
    "        if start_node not in start_node_to_row_idx:\n",
    "            print(f\"[WARNING] Start node {start_node} missing in primary_target_features_index.\")\n",
    "            continue\n",
    "\n",
    "        row_idx = start_node_to_row_idx[start_node]\n",
    "        primary_feat = primary_target_features_attr[row_idx]\n",
    "\n",
    "        for edge_path in paths:\n",
    "            if not edge_path:\n",
    "                continue\n",
    "            try:\n",
    "                last_edge = edge_path[-1]\n",
    "                final_tgt = int(target_edge_index[1, last_edge].item())\n",
    "\n",
    "                edge_choice = assign_edge_choices(\n",
    "                    edge_path, \n",
    "                    target_edge_index, \n",
    "                    target_edge_attr, \n",
    "                    primary_feat,\n",
    "                    node_dim=768,\n",
    "                    similarity_threshold=similarity_threshold\n",
    "                )\n",
    "\n",
    "                ind = creator.Individual({\n",
    "                    \"start\": start_node,\n",
    "                    \"goal\": final_tgt,\n",
    "                    \"edge_seq\": edge_path,\n",
    "                    \"edge_choice\": edge_choice,\n",
    "                    \"direction\": [True] * len(edge_path)\n",
    "                })\n",
    "\n",
    "                goal_to_individuals[final_tgt].append(ind)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] Failed to resolve final_tgt for path: {e}\")\n",
    "\n",
    "    print(f\"[LOG] Generated {len(goal_to_individuals)} goal groups with individuals\")\n",
    "    total_individuals = sum(len(v) for v in goal_to_individuals.values())\n",
    "    print(f\"[LOG] Total individuals created: {total_individuals}\")\n",
    "\n",
    "    printed = 0\n",
    "    for goal, inds in goal_to_individuals.items():\n",
    "        print(f\"  [Goal Node {goal}] ({len(inds)} individuals)\")\n",
    "        for i, ind in enumerate(inds[:3]):\n",
    "            print(f\"    Individual {i}: Start={ind['start']}, Edge Seq={ind['edge_seq']}, Edge Choice={ind['edge_choice']}\")\n",
    "        printed += len(inds)\n",
    "        if printed >= 10:\n",
    "            print(\"  ... (truncated)\")\n",
    "            break\n",
    "    \n",
    "    return goal_to_individuals\n",
    "\n",
    "edge_cand_dict = defaultdict(list)\n",
    "for idx in range(target_edge_index.size(1)):\n",
    "    src = int(target_edge_index[0, idx].item())\n",
    "    tgt = int(target_edge_index[1, idx].item())\n",
    "    edge_cand_dict[(src, tgt)].append(idx)\n",
    "\n",
    "individuals_by_goal = separate_individuals_by_goal(\n",
    "    unified_paths_by_start=unified_paths_by_start,\n",
    "    target_edge_index=target_edge_index,\n",
    "    target_edge_attr=target_edge_attr,\n",
    "    primary_dict=primary_dict,\n",
    "    primary_target_features_attr=primary_target_features_attr,\n",
    "    primary_target_features_index=primary_target_features_index,\n",
    "    edge_cand_dict=edge_cand_dict,\n",
    "    similarity_threshold=0.8\n",
    ")\n",
    "\n",
    "for i, (goal_node, individuals) in enumerate(individuals_by_goal.items()):\n",
    "    print(f\"  Goal Node: {goal_node}, #Individuals: {len(individuals)}\")\n",
    "\n",
    "    n = len(individuals)\n",
    "\n",
    "    for j in range(min(5, n)):\n",
    "        indiv = individuals[j]\n",
    "        print(f\"    [Top {j}] Start={indiv['start']}, Edge Seq={indiv['edge_seq']}\")\n",
    "\n",
    "    if n > 5:\n",
    "        for j in range(max(0, n-5), n):\n",
    "            indiv = individuals[j]\n",
    "            print(f\"    [Bottom {j}] Start={indiv['start']}, Edge Seq={indiv['edge_seq']}\")\n",
    "\n",
    "    if i >= 4:\n",
    "        print(\"  ... (truncated)\")\n",
    "        break\n",
    "\n",
    "def compute_activation(norm, alpha=2.0, beta=1.0):\n",
    "    return 2 * torch.sigmoid(alpha * (norm - beta))\n",
    "\n",
    "def evaluate_individual(individual, target_edge_index, target_edge_attr,\n",
    "                        primary_dict, node_goal_features, node_dim=768, device=None):\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    node_state = {}\n",
    "    start_node = individual[\"start\"]\n",
    "    goal_node = individual[\"goal\"]\n",
    "    edge_seq = individual[\"edge_seq\"]\n",
    "    edge_choice = individual[\"edge_choice\"]\n",
    "    direction_flags = individual[\"direction\"]\n",
    "\n",
    "    first_edge_seq = edge_seq[0]\n",
    "    first_direction = direction_flags[0]\n",
    "    first_src = int(target_edge_index[0, first_edge_seq].item())\n",
    "    first_tgt = int(target_edge_index[1, first_edge_seq].item())\n",
    "    if not first_direction:\n",
    "        first_src, first_tgt = first_tgt, first_src\n",
    "\n",
    "    if first_src not in primary_dict:\n",
    "        print(f\"[WARNING] Start node {first_src} not found in primary_dict.\")\n",
    "        return 1e6\n",
    "\n",
    "    node_state[first_src] = primary_dict[first_src].clone().to(device)\n",
    "\n",
    "    for i in range(len(edge_seq)):\n",
    "        try:\n",
    "            seq_edge_idx = edge_seq[i]\n",
    "            actual_edge_idx = edge_choice[i]\n",
    "\n",
    "            direction = direction_flags[i]\n",
    "            src = int(target_edge_index[0, seq_edge_idx].item())\n",
    "            tgt = int(target_edge_index[1, seq_edge_idx].item())\n",
    "            if not direction:\n",
    "                src, tgt = tgt, src\n",
    "\n",
    "            if src not in node_state:\n",
    "                continue\n",
    "\n",
    "            src_feat = node_state[src].clone()\n",
    "            edge_feat = target_edge_attr[actual_edge_idx, node_dim:].to(device)\n",
    "            norm = torch.norm(src_feat)\n",
    "            activation = compute_activation(norm, alpha=2.0, beta=1.0)\n",
    "\n",
    "            if tgt in node_state:\n",
    "                node_state[tgt] *= activation\n",
    "            else:\n",
    "                updated_feat = edge_feat * activation\n",
    "                node_state[tgt] = updated_feat.detach().clone()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Message passing failed at edge {edge_choice[i]}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if goal_node in node_state and goal_node in node_goal_features:\n",
    "        pred_feat = node_state[goal_node]\n",
    "        true_feat = node_goal_features[goal_node].to(device)\n",
    "        loss = torch.norm(pred_feat - true_feat, p=2).item()\n",
    "        pred_feat_out = pred_feat.detach().clone()\n",
    "    else:\n",
    "        loss = 1e6\n",
    "        pred_feat_out = None\n",
    "        print(f\"[RESULT] Goal node {goal_node} not reached or no ground truth. → Loss = {loss:.1e}\")\n",
    "\n",
    "    return loss, pred_feat_out\n",
    "\n",
    "def bfs_find_path_partial(src_node, tgt_node, target_edge_index, max_steps=100000):\n",
    "    adj_list = defaultdict(list)\n",
    "    for edge_idx in range(target_edge_index.size(1)):\n",
    "        src = int(target_edge_index[0, edge_idx].item())\n",
    "        tgt = int(target_edge_index[1, edge_idx].item())\n",
    "        adj_list[src].append((tgt, edge_idx))\n",
    "\n",
    "    queue = deque([(src_node, [])])\n",
    "    visited = set()\n",
    "    steps = 0\n",
    "\n",
    "    while queue:\n",
    "        if steps > max_steps:\n",
    "            print(f\"[WARNING] BFS exceeded {max_steps} steps without finding path from {src_node} to {tgt_node}\")\n",
    "            return None\n",
    "        steps += 1\n",
    "\n",
    "        current_node, path_so_far = queue.popleft()\n",
    "\n",
    "        if current_node == tgt_node:\n",
    "            return path_so_far\n",
    "\n",
    "        if current_node in visited:\n",
    "            continue\n",
    "        visited.add(current_node)\n",
    "\n",
    "        for next_node, edge_idx in adj_list.get(current_node, []):\n",
    "            if next_node not in visited:\n",
    "                queue.append((next_node, path_so_far + [edge_idx]))\n",
    "\n",
    "    return None\n",
    "\n",
    "def mutate_individual_with_path_repair(individual, target_edge_index, target_edge_attr, edge_cand_dict,\n",
    "                                        primary_dict, similarity_threshold=0.8, node_dim=768, device=None):\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    edge_seq = individual[\"edge_seq\"]\n",
    "    edge_choice = individual[\"edge_choice\"]\n",
    "    direction_flags = individual[\"direction\"]\n",
    "\n",
    "    mutated = False\n",
    "    mutation_index = -1\n",
    "    repair_occurred = False\n",
    "\n",
    "    for i in range(len(edge_seq)):\n",
    "        src = int(target_edge_index[0, edge_seq[i]].item())\n",
    "        tgt = int(target_edge_index[1, edge_seq[i]].item())\n",
    "        key = (src, tgt)\n",
    "\n",
    "        if key not in edge_cand_dict or len(edge_cand_dict[key]) <= 1:\n",
    "            continue\n",
    "\n",
    "        current_feat = target_edge_attr[edge_seq[i], :node_dim].to(device)\n",
    "        candidates = [idx for idx in edge_cand_dict[key] if idx != edge_seq[i]]\n",
    "        random.shuffle(candidates)\n",
    "\n",
    "        for cand_idx in candidates:\n",
    "            cand_feat = target_edge_attr[cand_idx, :node_dim].to(device)\n",
    "            cos_sim = F.cosine_similarity(current_feat, cand_feat, dim=0).item()\n",
    "            if cos_sim >= similarity_threshold:\n",
    "                edge_seq[i] = cand_idx\n",
    "                mutation_index = i\n",
    "                mutated = True\n",
    "                break\n",
    "\n",
    "    if not mutated:\n",
    "        return False\n",
    "\n",
    "    repaired_edge_seq = [edge_seq[0]]\n",
    "    repaired_direction_flags = [True]\n",
    "    repaired_edge_choice = [edge_choice[0]]\n",
    "\n",
    "    current_node = int(target_edge_index[1, edge_seq[0]].item())\n",
    "    repair_start_index = 1\n",
    "\n",
    "    for i in range(1, len(edge_seq)):\n",
    "        prev_edge = repaired_edge_seq[-1]\n",
    "        prev_tgt = int(target_edge_index[1, prev_edge].item())\n",
    "\n",
    "        this_edge = edge_seq[i]\n",
    "        this_src = int(target_edge_index[0, this_edge].item())\n",
    "        this_tgt = int(target_edge_index[1, this_edge].item())\n",
    "\n",
    "        if prev_tgt != this_src:\n",
    "            print(f\"[WARNING] Disconnection detected at step {i}: {prev_tgt} -> {this_src}. Attempting repair...\")\n",
    "            repair_path = bfs_find_path_partial(prev_tgt, this_src, target_edge_index)\n",
    "            if repair_path is None:\n",
    "                print(f\"[ERROR] Failed to repair path from {prev_tgt} to {this_src}.\")\n",
    "                return False\n",
    "            repair_occurred = True\n",
    "\n",
    "            for repair_edge_idx in repair_path:\n",
    "                repair_src = int(target_edge_index[0, repair_edge_idx].item())\n",
    "                repair_tgt = int(target_edge_index[1, repair_edge_idx].item())\n",
    "\n",
    "                key = (repair_src, repair_tgt)\n",
    "                candidates = edge_cand_dict.get(key, [])\n",
    "                if not candidates:\n",
    "                    key = (repair_tgt, repair_src)\n",
    "                    candidates = edge_cand_dict.get(key, [])\n",
    "                    direction = False\n",
    "                else:\n",
    "                    direction = True\n",
    "\n",
    "                if candidates:\n",
    "                    if len(repaired_edge_seq) > 0:\n",
    "                        prev_edge_idx = repaired_edge_seq[-1]\n",
    "                        prev_feat = target_edge_attr[prev_edge_idx, node_dim:].to(device)\n",
    "                    else:\n",
    "                        print(\"[ERROR] Broken path detected at first edge — no prior edge to base similarity on.\")\n",
    "                        return False\n",
    "                    \n",
    "                    similarities = [F.cosine_similarity(prev_feat, target_edge_attr[c, :node_dim].to(device), dim=0).item() for c in candidates]\n",
    "                    above_threshold = [(j, sim) for j, sim in enumerate(similarities) if sim >= similarity_threshold]\n",
    "                    if above_threshold:\n",
    "                        chosen_idx = random.choice(above_threshold)[0]\n",
    "                        chosen = candidates[chosen_idx]\n",
    "                    else:\n",
    "                        chosen_idx = int(torch.tensor(similarities).argmax().item())\n",
    "                        chosen = candidates[chosen_idx]\n",
    "                else:\n",
    "                    chosen = 0\n",
    "\n",
    "                print(f\"[DEBUG] Path repairing step {i}, key={key}, candidates={candidates}\")\n",
    "                print(f\"[DEBUG] Repaired edge_choice: {chosen}\")\n",
    "\n",
    "                repaired_edge_seq.append(repair_edge_idx)\n",
    "                repaired_direction_flags.append(direction)\n",
    "                repaired_edge_choice.append(chosen)\n",
    "\n",
    "                prev_tgt = repair_tgt if direction else repair_src\n",
    "                current_node = prev_tgt\n",
    "\n",
    "            repair_start_index = i\n",
    "\n",
    "        else:\n",
    "            repaired_edge_seq.append(this_edge)\n",
    "            repaired_direction_flags.append(True)\n",
    "            repaired_edge_choice.append(edge_choice[i])\n",
    "\n",
    "        current_node = this_tgt\n",
    "\n",
    "    recalc_start = mutation_index + 1 if mutation_index >= 0 else i\n",
    "    if recalc_start >= len(repaired_edge_seq):\n",
    "        print(\"[NOTE] No recalculation needed; recalc_start exceeds sequence length.\")\n",
    "        individual[\"edge_seq\"] = repaired_edge_seq\n",
    "        individual[\"direction\"] = repaired_direction_flags\n",
    "        individual[\"edge_choice\"] = repaired_edge_choice\n",
    "    else:\n",
    "        prev_edge_idx = repaired_edge_seq[recalc_start - 1]\n",
    "        prev_feat = target_edge_attr[prev_edge_idx, node_dim:].to(device)\n",
    "\n",
    "        for i in range(recalc_start, len(repaired_edge_seq)):\n",
    "            edge_idx = repaired_edge_seq[i]\n",
    "            direction = repaired_direction_flags[i]\n",
    "\n",
    "            src = int(target_edge_index[0, edge_idx].item())\n",
    "            tgt = int(target_edge_index[1, edge_idx].item())\n",
    "            key = (src, tgt) if direction else (tgt, src)\n",
    "            candidates = edge_cand_dict.get(key, [])\n",
    "\n",
    "            if candidates:\n",
    "                similarities = [F.cosine_similarity(prev_feat, target_edge_attr[c, :node_dim].to(device), dim=0).item()\n",
    "                                for c in candidates]\n",
    "                above_threshold = [(j, sim) for j, sim in enumerate(similarities) if sim >= similarity_threshold]\n",
    "                if above_threshold:\n",
    "                    chosen_idx = random.choice(above_threshold)[0]\n",
    "                    chosen = candidates[chosen_idx]\n",
    "                else:\n",
    "                    chosen_idx = int(torch.tensor(similarities).argmax().item())\n",
    "                    chosen = candidates[chosen_idx]\n",
    "\n",
    "            else:\n",
    "                chosen = 0\n",
    "\n",
    "            print(f\"[DEBUG] Recalculating step {i}, key={key}, candidates={candidates}\")\n",
    "            print(f\"[DEBUG] Recalculated edge_choice: {chosen}\")\n",
    "\n",
    "            repaired_edge_choice[i] = chosen\n",
    "            prev_edge_idx = edge_idx\n",
    "            prev_feat = target_edge_attr[edge_idx, node_dim:].to(device)\n",
    "\n",
    "        individual[\"edge_seq\"] = repaired_edge_seq\n",
    "        individual[\"direction\"] = repaired_direction_flags\n",
    "        individual[\"edge_choice\"] = repaired_edge_choice\n",
    "\n",
    "    print(\"[REPAIR_point_mutation] Path repair completed successfully.\")\n",
    "    print(f\"[REPAIR_point_mutation] Final edge_seq: {individual['edge_seq']}\")\n",
    "    print(f\"[REPAIR_point_mutation] Final direction: {individual['direction']}\")\n",
    "    print(f\"[REPAIR_point_mutation] Final edge_choice: {individual['edge_choice']}\")\n",
    "\n",
    "    if mutated and not repair_occurred:\n",
    "        print(\"[STATUS_point_mutation] Mutation succeeded without repair\")\n",
    "    elif not mutated and repair_occurred:\n",
    "        print(\"[STATUS_point_mutation] Mutation failed, repair applied\")\n",
    "    elif mutated and repair_occurred:\n",
    "        print(\"[STATUS_point_mutation] Mutation succeeded with repair\")\n",
    "\n",
    "    def check_path_validity(seq, choice, directions, label):\n",
    "        for i in range(len(seq) - 1):\n",
    "            idx1 = seq[i]\n",
    "            idx2 = choice[i + 1]\n",
    "            tgt1 = int(target_edge_index[1, idx1].item()) if directions[i] else int(target_edge_index[0, idx1].item())\n",
    "            src2 = int(target_edge_index[0, idx2].item()) if directions[i + 1] else int(target_edge_index[1, idx2].item())\n",
    "            if tgt1 != src2:\n",
    "                print(f\"[ERROR] Invalid path in {label}: {tgt1} -> {src2} at step {i} -> {i+1}\")\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    is_seq_valid = check_path_validity(individual[\"edge_seq\"], individual[\"edge_seq\"], individual[\"direction\"], \"edge_seq\")\n",
    "    is_choice_valid = check_path_validity(individual[\"edge_seq\"], individual[\"edge_choice\"], individual[\"direction\"], \"edge_choice\")\n",
    "\n",
    "    start_node = individual[\"start\"]\n",
    "    goal_node = individual[\"goal\"]\n",
    "    first_edge = individual[\"edge_seq\"][0]\n",
    "    last_edge = individual[\"edge_choice\"][-1]\n",
    "    actual_start = int(target_edge_index[0, first_edge].item())\n",
    "    actual_goal = int(target_edge_index[1, last_edge].item())\n",
    "\n",
    "    if actual_start != start_node:\n",
    "        print(f\"[ERROR] Start node mismatch: expected {start_node}, got {actual_start}\")\n",
    "        return False\n",
    "    if actual_goal != goal_node:\n",
    "        print(f\"[ERROR] Goal node mismatch: expected {goal_node}, got {actual_goal}\")\n",
    "        return False\n",
    "    if not (is_seq_valid and is_choice_valid):\n",
    "        return False\n",
    "\n",
    "    print(\"[VALIDATION_point_mutation] Final path successfully validated.\")\n",
    "    return True\n",
    "\n",
    "def reroute_middle_segment_via_repair(individual, target_edge_index, target_edge_attr, edge_cand_dict, primary_dict,\n",
    "                                      similarity_threshold=0.8, node_dim=768, bfs_find_path_partial=None, device=None):\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    edge_seq = individual[\"edge_seq\"]\n",
    "    edge_choice = individual[\"edge_choice\"]\n",
    "    direction_flags = individual[\"direction\"]\n",
    "\n",
    "    if len(edge_seq) < 2:\n",
    "        return False\n",
    "\n",
    "    first_edge = edge_seq[0]\n",
    "    last_edge = edge_seq[-1]\n",
    "    first_dir = direction_flags[0]\n",
    "    last_dir = direction_flags[-1]\n",
    "    first_choice = edge_choice[0]\n",
    "    last_choice = edge_choice[-1]\n",
    "\n",
    "    first_node = int(target_edge_index[1, first_edge].item()) if first_dir else int(target_edge_index[0, first_edge].item())\n",
    "    last_node = int(target_edge_index[0, last_edge].item()) if last_dir else int(target_edge_index[1, last_edge].item())\n",
    "\n",
    "    repair_path = bfs_find_path_partial(first_node, last_node, target_edge_index)\n",
    "    if repair_path is None:\n",
    "        return False\n",
    "\n",
    "    repaired_edge_seq = [first_edge]\n",
    "    repaired_direction_flags = [first_dir]\n",
    "    repaired_edge_choice = [first_choice]\n",
    "\n",
    "    current_node = first_node\n",
    "    prev_tgt = current_node\n",
    "\n",
    "    for repair_edge_idx in repair_path:\n",
    "        src = int(target_edge_index[0, repair_edge_idx].item())\n",
    "        tgt = int(target_edge_index[1, repair_edge_idx].item())\n",
    "\n",
    "        if src == current_node:\n",
    "            direction = True\n",
    "            next_node = tgt\n",
    "        elif tgt == current_node:\n",
    "            direction = False\n",
    "            next_node = src\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        key = (src, tgt) if direction else (tgt, src)\n",
    "        candidates = edge_cand_dict.get(key, [])\n",
    "        if candidates:\n",
    "            if len(repaired_edge_seq) > 0:\n",
    "                prev_edge_idx = repaired_edge_seq[-1]\n",
    "                prev_feat = target_edge_attr[prev_edge_idx, node_dim:].to(device)\n",
    "            else:\n",
    "                prev_feat = target_edge_attr[repair_edge_idx, :node_dim].to(device)\n",
    "            similarities = [F.cosine_similarity(prev_feat, target_edge_attr[c, :node_dim].to(device), dim=0).item() for c in candidates]\n",
    "            above_threshold = [(j, sim) for j, sim in enumerate(similarities) if sim >= similarity_threshold]\n",
    "            if above_threshold:\n",
    "                choice = random.choice(above_threshold)[0]\n",
    "                choice_idx = candidates[choice]\n",
    "            else:\n",
    "                choice = int(torch.tensor(similarities).argmax().item())\n",
    "                choice_idx = candidates[choice]\n",
    "        else:\n",
    "            choice_idx = 0\n",
    "\n",
    "        print(f\"[DEBUG] Segment mutation recalculating step {i}, key={key}, candidates={candidates}\")\n",
    "        print(f\"[DEBUG] Segment mutation recalculated edge_choice: {choice_idx}\")\n",
    "\n",
    "        repaired_edge_seq.append(repair_edge_idx)\n",
    "        repaired_direction_flags.append(direction)\n",
    "        repaired_edge_choice.append(choice_idx)\n",
    "\n",
    "        current_node = next_node\n",
    "        prev_tgt = current_node\n",
    "\n",
    "    key = (int(target_edge_index[0, last_edge].item()), int(target_edge_index[1, last_edge].item())) if last_dir \\\n",
    "        else (int(target_edge_index[1, last_edge].item()), int(target_edge_index[0, last_edge].item()))\n",
    "    candidates = edge_cand_dict.get(key, [])\n",
    "\n",
    "    if candidates:\n",
    "        prev_edge_idx = repaired_edge_seq[-1]\n",
    "        prev_feat = target_edge_attr[prev_edge_idx, node_dim:].to(device)\n",
    "        similarities = [F.cosine_similarity(prev_feat, target_edge_attr[c, :node_dim].to(device), dim=0).item() for c in candidates]\n",
    "        above_threshold = [(j, sim) for j, sim in enumerate(similarities) if sim >= similarity_threshold]\n",
    "        if above_threshold:\n",
    "            choice = random.choice(above_threshold)[0]\n",
    "            last_choice = candidates[choice]\n",
    "        else:\n",
    "            choice = int(torch.tensor(similarities).argmax().item())\n",
    "            last_choice = candidates[choice]\n",
    "    else:\n",
    "        last_choice = 0\n",
    "\n",
    "    print(f\"[DEBUG] Segment mutation step {i}, key={key}, candidates={candidates}\")\n",
    "    print(f\"[DEBUG] Segment mutation edge_choice: {last_choice}\")\n",
    "\n",
    "    repaired_edge_seq.append(last_edge)\n",
    "    repaired_direction_flags.append(last_dir)\n",
    "    repaired_edge_choice.append(last_choice)\n",
    "\n",
    "    individual[\"edge_seq\"] = repaired_edge_seq\n",
    "    individual[\"direction\"] = repaired_direction_flags\n",
    "    individual[\"edge_choice\"] = repaired_edge_choice\n",
    "\n",
    "    print(\"[REPAIR_segment_mutation] Middle segment rerouted and repaired successfully.\")\n",
    "    print(f\"[REPAIR_segment_mutation] Final edge_seq: {individual['edge_seq']}\")\n",
    "    print(f\"[REPAIR_segment_mutation] Final direction: {individual['direction']}\")\n",
    "    print(f\"[REPAIR_segment_mutation] Final edge_choice: {individual['edge_choice']}\")\n",
    "\n",
    "    def check_path_validity(seq, choice, directions, label):\n",
    "        for i in range(len(seq) - 1):\n",
    "            idx1 = seq[i]\n",
    "            idx2 = choice[i + 1]\n",
    "            tgt1 = int(target_edge_index[1, idx1].item()) if directions[i] else int(target_edge_index[0, idx1].item())\n",
    "            src2 = int(target_edge_index[0, idx2].item()) if directions[i + 1] else int(target_edge_index[1, idx2].item())\n",
    "            if tgt1 != src2:\n",
    "                print(f\"[ERROR] Invalid path in {label}: {tgt1} -> {src2} at step {i} -> {i+1}\")\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    is_seq_valid = check_path_validity(individual[\"edge_seq\"], individual[\"edge_seq\"], individual[\"direction\"], \"edge_seq\")\n",
    "    is_choice_valid = check_path_validity(individual[\"edge_seq\"], individual[\"edge_choice\"], individual[\"direction\"], \"edge_choice\")\n",
    "\n",
    "    start_node = individual[\"start\"]\n",
    "    goal_node = individual[\"goal\"]\n",
    "    first_edge = individual[\"edge_seq\"][0]\n",
    "    last_edge = individual[\"edge_choice\"][-1]\n",
    "    actual_start = int(target_edge_index[0, first_edge].item())\n",
    "    actual_goal = int(target_edge_index[1, last_edge].item())\n",
    "\n",
    "    if actual_start != start_node:\n",
    "        print(f\"[ERROR] Start node mismatch: expected {start_node}, got {actual_start}\")\n",
    "        return False\n",
    "    if actual_goal != goal_node:\n",
    "        print(f\"[ERROR] Goal node mismatch: expected {goal_node}, got {actual_goal}\")\n",
    "        return False\n",
    "    if not (is_seq_valid and is_choice_valid):\n",
    "        return False\n",
    "\n",
    "    print(\"[VALIDATION_segment_mutation] Final path successfully validated.\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def compute_diversity(individual, population, edge_usage_counts=None,\n",
    "                      path_cache=None, length_cache=None):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    start = individual[\"start\"]\n",
    "    goal = individual[\"goal\"]\n",
    "    edge_seq = individual[\"edge_seq\"]\n",
    "    edge_choice = individual[\"edge_choice\"]\n",
    "\n",
    "    def extract_node_path(indiv):\n",
    "        path = []\n",
    "        for i, edge_idx in enumerate(indiv[\"edge_seq\"]):\n",
    "            src = int(target_edge_index[0, edge_idx].item())\n",
    "            tgt = int(target_edge_index[1, edge_idx].item())\n",
    "            path.append(src if indiv[\"direction\"][i] else tgt)\n",
    "        last_edge = indiv[\"edge_seq\"][-1]\n",
    "        last_tgt = int(target_edge_index[1, last_edge].item())\n",
    "        path.append(last_tgt)\n",
    "        return path\n",
    "\n",
    "    indiv_id = id(individual)\n",
    "    if path_cache and indiv_id in path_cache:\n",
    "        this_path = path_cache[indiv_id]\n",
    "        path_length = length_cache[indiv_id]\n",
    "    else:\n",
    "        this_path_list = extract_node_path(individual)\n",
    "        this_path = set(this_path_list)\n",
    "        path_length = len(this_path_list)\n",
    "\n",
    "    path_scores = []\n",
    "    start_diff = 0\n",
    "    goal_diff = 0\n",
    "    length_diffs = []\n",
    "\n",
    "    for other in population:\n",
    "        if other is individual:\n",
    "            continue\n",
    "\n",
    "        other_id = id(other)\n",
    "        if path_cache and other_id in path_cache:\n",
    "            other_path = path_cache[other_id]\n",
    "            other_len = length_cache[other_id]\n",
    "        else:\n",
    "            other_path_list = extract_node_path(other)\n",
    "            other_path = set(other_path_list)\n",
    "            other_len = len(other_path_list)\n",
    "\n",
    "        jaccard = 1.0 - len(this_path & other_path) / max(1, len(this_path | other_path))\n",
    "        path_scores.append(jaccard)\n",
    "\n",
    "        if other[\"start\"] != start:\n",
    "            start_diff += 1\n",
    "        if other[\"goal\"] != goal:\n",
    "            goal_diff += 1\n",
    "\n",
    "        length_diffs.append(abs(other_len - path_length))\n",
    "\n",
    "    path_diversity = np.mean(path_scores) if path_scores else 0\n",
    "    start_div = start_diff / max(1, len(population))\n",
    "    goal_div = goal_diff / max(1, len(population))\n",
    "    length_penalty = 1.0 / (1.0 + np.mean(length_diffs)) if length_diffs else 1.0\n",
    "\n",
    "    edge_rarity_score = 0\n",
    "    if edge_usage_counts:\n",
    "        for e in edge_choice:\n",
    "            freq = edge_usage_counts.get(e, 1)\n",
    "            edge_rarity_score += 1.0 / freq\n",
    "        edge_rarity_score /= len(edge_choice)\n",
    "\n",
    "    total_diversity = (\n",
    "        0.25 * path_diversity +\n",
    "        0.15 * start_div +\n",
    "        0.15 * goal_div +\n",
    "        0.25 * length_penalty +\n",
    "        0.20 * edge_rarity_score\n",
    "    )\n",
    "\n",
    "    return total_diversity\n",
    "\n",
    "def evaluate_individual_with_diversity(individual, target_edge_index, target_edge_attr,\n",
    "                                       primary_dict, node_goal_features,\n",
    "                                       population=None, edge_usage_counts=None,\n",
    "                                       node_dim=768, device=None):\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    loss = evaluate_individual(\n",
    "        individual,\n",
    "        target_edge_index=target_edge_index,\n",
    "        target_edge_attr=target_edge_attr,\n",
    "        primary_dict=primary_dict,\n",
    "        node_goal_features=node_goal_features,\n",
    "        node_dim=node_dim,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    diversity = compute_diversity(individual, population, edge_usage_counts=edge_usage_counts)\n",
    "\n",
    "    return (loss, -diversity)\n",
    "\n",
    "def find_best_combinations_by_goal_beam(population, node_goal_features, beam_k=5, max_steps=10, device=\"cuda\"):\n",
    "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    goal_to_individuals = {}\n",
    "    for ind in population:\n",
    "        if ind.get(\"pred_feat\") is not None:\n",
    "            goal_to_individuals.setdefault(ind[\"goal\"], []).append(ind)\n",
    "\n",
    "    best_combinations = {}\n",
    "\n",
    "    for goal, inds in goal_to_individuals.items():\n",
    "        true_feat = node_goal_features.get(goal)\n",
    "        if true_feat is None or len(inds) == 0:\n",
    "            continue\n",
    "\n",
    "        true_feat = true_feat.to(device)\n",
    "        pred_feats = [ind[\"pred_feat\"].to(device) for ind in inds]\n",
    "        inds_tensor = list(inds)\n",
    "\n",
    "        print(f\"[INFO] Processing goal node: {goal} (candidates: {len(pred_feats)})\")\n",
    "        print(f\"[INFO] true_feat shape: {true_feat.shape}\")\n",
    "\n",
    "        beam = [([i], pred_feats[i]) for i in range(len(pred_feats))]  # ([index_list], sum_tensor)\n",
    "        best_combo = None\n",
    "        best_dist = float('inf')\n",
    "\n",
    "        for step in range(1, max_steps + 1):\n",
    "            candidates = []\n",
    "\n",
    "            print(f\"[STEP {step}] Beam size = {len(beam)}\")\n",
    "\n",
    "            for idx_list, sum_tensor in beam:\n",
    "                used_set = set(idx_list)\n",
    "                for j in range(len(pred_feats)):\n",
    "                    if j in used_set:\n",
    "                        continue\n",
    "                    new_list = idx_list + [j]\n",
    "                    new_sum = sum_tensor + pred_feats[j]\n",
    "                    mean_feat = new_sum / len(new_list)\n",
    "\n",
    "                    dist = F.pairwise_distance(mean_feat.unsqueeze(0), true_feat.unsqueeze(0), p=2).item()\n",
    "                    candidates.append((new_list, new_sum, dist))\n",
    "\n",
    "            print(f\"[LOG] Step {step} - top 5 candidates:\")\n",
    "            for k, (idxs, sum_tensor, dist_val) in enumerate(candidates[:5]):\n",
    "                mean_feat = sum_tensor / len(idxs)\n",
    "                print(f\"  [{k+1}] +{idxs[-1]} -> dist={dist_val:.6f} | mean_feat.shape={mean_feat.shape}, sum_tensor.shape={sum_tensor.shape}\")\n",
    "\n",
    "            if not candidates:\n",
    "                break\n",
    "\n",
    "            candidates.sort(key=lambda x: x[2])\n",
    "            beam = [(c[0], c[1]) for c in candidates[:beam_k]]\n",
    "\n",
    "            print(f\"[INFO] Beam updated: top-{beam_k} candidates retained.\")\n",
    "\n",
    "            top_combo, _, top_dist = candidates[0]\n",
    "            if top_dist < best_dist:\n",
    "                best_combo = top_combo\n",
    "                best_dist = top_dist\n",
    "\n",
    "        if best_combo is not None:\n",
    "            best_combinations[goal] = {\n",
    "                \"combination\": [inds_tensor[i] for i in best_combo],\n",
    "                \"distance\": best_dist\n",
    "            }\n",
    "            print(f\"[COMBO] Goal={goal} | Best combination length={len(best_combo)} | Distance={best_dist:.6f}\")\n",
    "\n",
    "    return best_combinations\n",
    "\n",
    "def build_edge_usage_counts(population):\n",
    "    all_edges = []\n",
    "    for ind in population:\n",
    "        all_edges.extend(ind[\"edge_choice\"])\n",
    "    return Counter(all_edges)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[LOG] Using device: {device}\")\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate_individual,\n",
    "                 target_edge_index=target_edge_index,\n",
    "                 target_edge_attr=target_edge_attr,\n",
    "                 primary_dict=primary_dict,\n",
    "                 node_goal_features=node_goal_features,\n",
    "                 node_dim=768,\n",
    "                 device=device)\n",
    "\n",
    "toolbox.register(\"mutate\", mutate_individual_with_path_repair,\n",
    "                target_edge_index=target_edge_index,\n",
    "                target_edge_attr=target_edge_attr,\n",
    "                edge_cand_dict=edge_cand_dict,\n",
    "                primary_dict=primary_dict,\n",
    "                similarity_threshold=0.8,\n",
    "                node_dim=768,\n",
    "                device=device)\n",
    "\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "population = [ind for individuals in individuals_by_goal.values() for ind in individuals]\n",
    "print(f\"[LOG] Total initial individuals: {len(population)}\")\n",
    "\n",
    "NGEN = 2\n",
    "MUTPB = 0.2\n",
    "\n",
    "latest_population_info = []\n",
    "\n",
    "for gen in range(1, NGEN + 1):\n",
    "    print(f\"[GENERATION {gen}]\")\n",
    "\n",
    "    fitnesses = []\n",
    "    for ind in population:\n",
    "        loss, pred_feat_out = toolbox.evaluate(ind)\n",
    "        fitnesses.append(loss)\n",
    "        ind[\"pred_feat\"] = pred_feat_out.detach()\n",
    "\n",
    "    path_cache = {}\n",
    "    length_cache = {}\n",
    "\n",
    "    for ind in population:\n",
    "        path = []\n",
    "        for i, edge_idx in enumerate(ind[\"edge_seq\"]):\n",
    "            src = int(target_edge_index[0, edge_idx].item())\n",
    "            tgt = int(target_edge_index[1, edge_idx].item())\n",
    "            path.append(src if ind[\"direction\"][i] else tgt)\n",
    "        last_edge = ind[\"edge_seq\"][-1]\n",
    "        path.append(int(target_edge_index[1, last_edge].item()))\n",
    "        path_cache[id(ind)] = set(path)\n",
    "        length_cache[id(ind)] = len(path)\n",
    "\n",
    "    edge_usage_counts = build_edge_usage_counts(population)\n",
    "\n",
    "    for ind, loss in zip(population, fitnesses):\n",
    "        diversity = compute_diversity(ind, population,\n",
    "                                      edge_usage_counts=edge_usage_counts,\n",
    "                                      path_cache=path_cache,\n",
    "                                      length_cache=length_cache)\n",
    "        ind.fitness.values = (loss, -diversity)\n",
    "\n",
    "    fitness_values = [ind.fitness.values[0] for ind in population]\n",
    "    avg_fitness = sum(fitness_values) / len(fitness_values)\n",
    "    min_fitness = min(fitness_values)\n",
    "    print(f\"[STATS] Avg fitness: {avg_fitness:.6f} | Min fitness: {min_fitness:.6f}\")\n",
    "\n",
    "    offspring = toolbox.select(population, len(population))  # selNSGA2\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    new_offspring = []\n",
    "\n",
    "    temp_fitnesses = [ind.fitness.values[0] if ind.fitness.valid else toolbox.evaluate(ind) for ind in offspring]\n",
    "    fitness_threshold = sorted(f[0] if isinstance(f, tuple) else f for f in temp_fitnesses)[int(0.8 * len(temp_fitnesses))]\n",
    "\n",
    "    for mutant, temp_fit in zip(offspring, temp_fitnesses):\n",
    "        if random.random() < MUTPB:\n",
    "            original = toolbox.clone(mutant)\n",
    "            success = toolbox.mutate(mutant)\n",
    "\n",
    "            if success:\n",
    "                loss, pred_feat_out = toolbox.evaluate(mutant)\n",
    "                mutant[\"pred_feat\"] = pred_feat_out.detach()\n",
    "                mutant.fitness.values = (loss, -1.0)\n",
    "                print(f\"[LOG] Mutation success. Loss={loss:.6f}\")\n",
    "                new_offspring.append(mutant)\n",
    "            else:\n",
    "                if temp_fit > fitness_threshold and random.random() < 0.5:\n",
    "                    repaired = reroute_middle_segment_via_repair(\n",
    "                        individual=mutant,\n",
    "                        target_edge_index=target_edge_index,\n",
    "                        target_edge_attr=target_edge_attr,\n",
    "                        edge_cand_dict=edge_cand_dict,\n",
    "                        primary_dict=primary_dict,\n",
    "                        similarity_threshold=0.8,\n",
    "                        node_dim=768,\n",
    "                        bfs_find_path_partial=bfs_find_path_partial,\n",
    "                        device=device\n",
    "                    )\n",
    "                    if repaired:\n",
    "                        loss, pred_feat_out = toolbox.evaluate(mutant)\n",
    "                        mutant[\"pred_feat\"] = pred_feat_out.detach()\n",
    "                        mutant.fitness.values = (loss, -1.0)\n",
    "                        print(f\"[LOG] Repair success. Loss={loss:.6f}\")\n",
    "                        new_offspring.append(mutant)\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(f\"[REPAIR-FAIL] Reroute attempt failed for mutant with start={mutant['start']}, goal={mutant['goal']}\")\n",
    "\n",
    "                loss, pred_feat_out = toolbox.evaluate(original)\n",
    "                original[\"pred_feat\"] = pred_feat_out.detach()\n",
    "                original.fitness.values = (loss, -1.0)\n",
    "                print(f\"[LOG] Mutation failed. Reverting to original. Loss={loss:.6f}\")\n",
    "                new_offspring.append(original)\n",
    "        else:\n",
    "            loss, pred_feat_out = toolbox.evaluate(mutant)\n",
    "            mutant[\"pred_feat\"] = pred_feat_out.detach()\n",
    "            mutant.fitness.values = (loss, -1.0)\n",
    "            print(f\"[LOG] No mutation. Keeping individual. Loss={loss:.6f}\")\n",
    "            new_offspring.append(mutant)\n",
    "\n",
    "    population[:] = new_offspring\n",
    "    path_cache = {}\n",
    "    length_cache = {}\n",
    "    for ind in population:\n",
    "        path = []\n",
    "        for i, edge_idx in enumerate(ind[\"edge_seq\"]):\n",
    "            src = int(target_edge_index[0, edge_idx].item())\n",
    "            tgt = int(target_edge_index[1, edge_idx].item())\n",
    "            path.append(src if ind[\"direction\"][i] else tgt)\n",
    "        last_edge = ind[\"edge_seq\"][-1]\n",
    "        path.append(int(target_edge_index[1, last_edge].item()))\n",
    "        path_cache[id(ind)] = set(path)\n",
    "        length_cache[id(ind)] = len(path)\n",
    "\n",
    "    edge_usage_counts = build_edge_usage_counts(population)\n",
    "    for ind in population:\n",
    "        loss, pred_feat_out = toolbox.evaluate(ind)\n",
    "        ind[\"pred_feat\"] = pred_feat_out.detach()\n",
    "        diversity = compute_diversity(ind, population,\n",
    "                                      edge_usage_counts=edge_usage_counts,\n",
    "                                      path_cache=path_cache,\n",
    "                                      length_cache=length_cache)\n",
    "        ind.fitness.values = (loss, -diversity)\n",
    "\n",
    "    best_combinations = find_best_combinations_by_goal_beam(\n",
    "        population=population,\n",
    "        node_goal_features=node_goal_features,\n",
    "        beam_k=50,\n",
    "        max_steps=20,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    latest_population_info = [(ind, ind.fitness.values) for ind in population]\n",
    "\n",
    "    best_fit = min(fit[0] for _, fit in latest_population_info)\n",
    "    print(f\"[RESULT] Best fitness at generation {gen}: {best_fit:.6f}\")\n",
    "\n",
    "best_individual, best_fitness = min(latest_population_info, key=lambda x: x[1])\n",
    "\n",
    "print(\"[FINAL] Best individual (summary):\")\n",
    "print(f\"  start: {best_individual['start']}\")\n",
    "print(f\"  goal: {best_individual['goal']}\")\n",
    "print(f\"  fitness: Loss = {best_fitness[0]:.6f}, Diversity = {-best_fitness[1]:.6f}\")\n",
    "print(f\"  edge_seq: {best_individual['edge_seq']}\")\n",
    "print(f\"  edge_choice: {best_individual['edge_choice']}\")\n",
    "\n",
    "save_dir = \"./data/evolution_output/YOUR_DIRECTORY_NAME_HERE\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "def tensor_to_serializable(obj):\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: tensor_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [tensor_to_serializable(v) for v in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(tensor_to_serializable(v) for v in obj)\n",
    "    return obj\n",
    "\n",
    "best_individual, best_fitness = min(latest_population_info, key=lambda x: x[1])\n",
    "best_individual_dict = dict(best_individual)\n",
    "best_individual_dict[\"fitness\"] = tensor_to_serializable(best_fitness)\n",
    "\n",
    "with open(os.path.join(save_dir, \"best_individual.json\"), \"w\") as f:\n",
    "    json.dump(tensor_to_serializable(best_individual_dict), f, indent=2)\n",
    "\n",
    "with open(os.path.join(save_dir, \"best_fitness.txt\"), \"w\") as f:\n",
    "    f.write(f\"Best Fitness (Final Loss): {best_fitness[0]:.6f}, Diversity: {-best_fitness[1]:.6f}\\n\")\n",
    "\n",
    "torch.save(best_individual_dict, os.path.join(save_dir, \"best_individual.pt\"))\n",
    "\n",
    "all_individuals_serialized = []\n",
    "for ind, fit in latest_population_info:\n",
    "    ind_dict = dict(ind)\n",
    "    ind_dict[\"fitness\"] = tensor_to_serializable(fit)\n",
    "    all_individuals_serialized.append(tensor_to_serializable(ind_dict))\n",
    "\n",
    "with open(os.path.join(save_dir, \"all_individuals.json\"), \"w\") as f:\n",
    "    json.dump(all_individuals_serialized, f, indent=2)\n",
    "\n",
    "best_individuals_by_pair = {}\n",
    "\n",
    "for ind, fit in latest_population_info:\n",
    "    start = ind[\"start\"]\n",
    "    goal = ind[\"goal\"]\n",
    "    key = (start, goal)\n",
    "\n",
    "    if key not in best_individuals_by_pair or fit < best_individuals_by_pair[key][1]:\n",
    "        best_individuals_by_pair[key] = (ind, fit)\n",
    "\n",
    "best_individuals_by_pair_serialized = {}\n",
    "\n",
    "for (start, goal), (best_ind, fit) in best_individuals_by_pair.items():\n",
    "    key_str = f\"start{start}_goal{goal}\"\n",
    "    ind_dict = dict(best_ind)\n",
    "    ind_dict[\"fitness\"] = tensor_to_serializable(fit)\n",
    "    best_individuals_by_pair_serialized[key_str] = tensor_to_serializable(ind_dict)\n",
    "\n",
    "save_path_json = os.path.join(save_dir, \"best_individuals_by_pair.json\")\n",
    "with open(save_path_json, \"w\") as f:\n",
    "    json.dump(best_individuals_by_pair_serialized, f, indent=2)\n",
    "\n",
    "save_path_pt = os.path.join(save_dir, \"best_individuals_by_pair.pt\")\n",
    "torch.save(best_individuals_by_pair_serialized, save_path_pt)\n",
    "\n",
    "print(f\"[LOG] Best individuals by (start, goal) saved to {save_path_json} and {save_path_pt}\")\n",
    "\n",
    "best_combinations_serialized = {}\n",
    "\n",
    "for goal, combo_info in best_combinations.items():\n",
    "    serialized = {\n",
    "        \"goal\": goal,\n",
    "        \"distance\": combo_info[\"distance\"],\n",
    "        \"combination\": [tensor_to_serializable(dict(ind)) for ind in combo_info[\"combination\"]]\n",
    "    }\n",
    "    best_combinations_serialized[str(goal)] = serialized\n",
    "\n",
    "save_path_combos = os.path.join(save_dir, \"best_combinations_by_goal.json\")\n",
    "with open(save_path_combos, \"w\") as f:\n",
    "    json.dump(best_combinations_serialized, f, indent=2)\n",
    "\n",
    "print(f\"[LOG] Best combinations by goal saved to {save_path_combos}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
